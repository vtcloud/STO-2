{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version now uses the new method of deriving the reference observations to be truely free of contaminating emission.\n",
    "\n",
    "The notebook EtaCar2_read_OTF_3801_L0.6_references_decontam.ipynb tests the method in more detail and compares it for single OTF strips to the conventional method.\n",
    "\n",
    "update 2/6/2019:\n",
    "Inserted smoothing of Tsys: pixel-tp-pixel jumps of more than thresh (=50) are set to 1E7. The subsequent arpls smoother ignores these pixels and replaces the values with a smoothed value. In addition, the entire Tsys spectra are smoothed, reducing its noise contribution. The associated error is estimated to be below 1%.\n",
    "\n",
    "update 3/19/2019:\n",
    "updated to STO_v34 to retrieve the correct coordinates for the [NII]-beams. Previously was a missing cos(dec) term in applying the offsets.\n",
    "\n",
    "update 4/22/2019\n",
    "Ongoing tuning of the arPLS baseline retrieval parameters.\n",
    "subversion might have the baseline correction method added to the end of the notebook name to differentiate between the versions.\n",
    "\n",
    "update 5/21/2019\n",
    "created a new cleaned Level 0.7 data product vm18. The cleaning now used the arPLS smoothing to determine which pixels need repair and replacement. Might work better than before since first results looked promising.\n",
    "\n",
    "update 8/26/2019\n",
    "The cleaning of the Level 0.7 data has been improved (?) again. The latest is a 2-step cleaning process, repSpike1D() added to STO2_v34, which was initiated to create a cleaned product in order for Youngmin's software to also run on the [NII] data. Further updates are still in the works.\n",
    "\n",
    "update 8/28/2019\n",
    "Added checking for mask entry before performing the baseline fit.\n",
    "\n",
    "update 11/14/2019 and before\n",
    "Added FITS file output of original format with additions.\n",
    "Added anothe ALS fitting with different parameters since implemented version does not neccessarily remove the baseline???\n",
    "In future, the ALS baseline fitting should be implemented with quality control to catch outliers, a.k.a., baseline fits that went wrong.\n",
    "\n",
    "update 2/20/2020\n",
    "Changed the ALS fitting of the resampled spectrum. Now the input spectrum has the masked pixels removed before the ALS fit in order to provide the correct fit and remove possible interference by spikes.\n",
    "\n",
    "update 2/21/2020\n",
    "Inserted another spike testing for the final spectrum after baseline fitting to flag bad pixels missed before.<br>\n",
    "Updated and tuned the baseline correction options. <br>\n",
    "Few additional minor changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-8891ec6e3af1>\n",
      "Last execution: Tue May 19 16:46:48 2020\n",
      "Eta Car: 287.58968,-0.63202\n",
      "Eta Car: 10h45m00.0s -59d41m00.0s\n",
      "Processing data for line:  CII 2\n",
      "reading excel data analysis sheet.\n",
      "Index(['drudir', '    dru', 'dhudir', '   dhu', 'dhucor', 'ohudir', '   ohu',\n",
      "       'orudir', '   oru', 'orucor', 'spdir', '  spec', ' spec2', 'orddir',\n",
      "       '   ord', 'ordcor', 'ohddir', '   ohd', 'dhddir', '   dhd', 'drddir',\n",
      "       '   drd', 'des ref1', 'des ref2', 'brange1[0]', 'brange1[1]',\n",
      "       'brange2[0]', 'brange2[1]', 'order1', 'order2', 'despike', 'despike2'],\n",
      "      dtype='object')\n",
      "(96,)\n",
      "mapdirs:  [3801 3803 3805 3807 3809 3811 3813 3815 3817 3819 3821 3823 3825 3827\n",
      " 3829 3831 3833 3835 3837 3839 3841 3843 3845 3847 3849 3851 3853 3855\n",
      " 3857 3859 3861 3863 3865 3867 3869 3871 3873 3875 3877 3879 3881 3883\n",
      " 3885 3887 3889 3891 3893 3895 3897 3899 3901 3903 3909 3911 3913 3915\n",
      " 3917 3919 3921 3923 3925 3927 3929 3931 3933 3935 3937 3939 3941 3943\n",
      " 3945 3947 3949 3951 3953 3955 3957 3959 3961 3963 3965 3967 3969 3971\n",
      " 3973 3975 3977 3979 3981 3983 3985 3987 3989 3991]\n",
      "\n",
      "processing OTF scan : 03801 with reference scans dirs: 03800 and 03802\n",
      "\n",
      "processing OTF scan : 03803 with reference scans dirs: 03802 and 03804\n",
      "\n",
      "processing OTF scan : 03805 with reference scans dirs: 03804 and 03806\n",
      "\n",
      "processing OTF scan : 03807 with reference scans dirs: 03806 and 03808\n",
      "\n",
      "processing OTF scan : 03809 with reference scans dirs: 03808 and 03810\n",
      "\n",
      "processing OTF scan : 03811 with reference scans dirs: 03810 and 03812\n",
      "\n",
      "processing OTF scan : 03813 with reference scans dirs: 03812 and 03814\n",
      "\n",
      "processing OTF scan : 03815 with reference scans dirs: 03814 and 03816\n",
      "\n",
      "processing OTF scan : 03817 with reference scans dirs: 03816 and 03818\n",
      "\n",
      "processing OTF scan : 03819 with reference scans dirs: 03818 and 03820\n",
      "\n",
      "processing OTF scan : 03821 with reference scans dirs: 03820 and 03822\n",
      "\n",
      "processing OTF scan : 03823 with reference scans dirs: 03822 and 03824\n",
      "\n",
      "processing OTF scan : 03825 with reference scans dirs: 03824 and 03826\n",
      "\n",
      "processing OTF scan : 03827 with reference scans dirs: 03826 and 03828\n",
      "\n",
      "processing OTF scan : 03829 with reference scans dirs: 03828 and 03830\n",
      "\n",
      "processing OTF scan : 03831 with reference scans dirs: 03830 and 03832\n",
      "\n",
      "processing OTF scan : 03833 with reference scans dirs: 03832 and 03834\n",
      "\n",
      "processing OTF scan : 03835 with reference scans dirs: 03834 and 03836\n",
      "\n",
      "processing OTF scan : 03837 with reference scans dirs: 03836 and 03838\n",
      "\n",
      "processing OTF scan : 03839 with reference scans dirs: 03838 and 03840\n",
      "\n",
      "processing OTF scan : 03841 with reference scans dirs: 03840 and 03842\n",
      "\n",
      "processing OTF scan : 03843 with reference scans dirs: 03842 and 03844\n",
      "\n",
      "processing OTF scan : 03845 with reference scans dirs: 03844 and 03846\n",
      "\n",
      "processing OTF scan : 03847 with reference scans dirs: 03846 and 03848\n",
      "\n",
      "processing OTF scan : 03849 with reference scans dirs: 03848 and 03850\n",
      "\n",
      "processing OTF scan : 03851 with reference scans dirs: 03850 and 03852\n",
      "\n",
      "processing OTF scan : 03853 with reference scans dirs: 03852 and 03854\n",
      "\n",
      "processing OTF scan : 03855 with reference scans dirs: 03854 and 03856\n",
      "\n",
      "processing OTF scan : 03857 with reference scans dirs: 03856 and 03858\n",
      "\n",
      "processing OTF scan : 03859 with reference scans dirs: 03858 and 03860\n",
      "\n",
      "processing OTF scan : 03861 with reference scans dirs: 03860 and 03862\n",
      "\n",
      "processing OTF scan : 03863 with reference scans dirs: 03862 and 03864\n",
      "\n",
      "processing OTF scan : 03865 with reference scans dirs: 03864 and 03866\n",
      "\n",
      "processing OTF scan : 03867 with reference scans dirs: 03866 and 03868\n",
      "\n",
      "processing OTF scan : 03869 with reference scans dirs: 03868 and 03870\n",
      "\n",
      "processing OTF scan : 03871 with reference scans dirs: 03870 and 03872\n",
      "\n",
      "processing OTF scan : 03873 with reference scans dirs: 03872 and 03874\n",
      "\n",
      "processing OTF scan : 03875 with reference scans dirs: 03874 and 03876\n",
      "\n",
      "processing OTF scan : 03877 with reference scans dirs: 03876 and 03878\n",
      "\n",
      "processing OTF scan : 03879 with reference scans dirs: 03878 and 03880\n",
      "\n",
      "processing OTF scan : 03881 with reference scans dirs: 03880 and 03882\n",
      "\n",
      "processing OTF scan : 03883 with reference scans dirs: 03882 and 03884\n",
      "\n",
      "processing OTF scan : 03885 with reference scans dirs: 03884 and 03886\n",
      "\n",
      "processing OTF scan : 03887 with reference scans dirs: 03886 and 03888\n",
      "\n",
      "processing OTF scan : 03889 with reference scans dirs: 03888 and 03890\n",
      "\n",
      "processing OTF scan : 03891 with reference scans dirs: 03890 and 03892\n",
      "\n",
      "processing OTF scan : 03893 with reference scans dirs: 03892 and 03894\n",
      "\n",
      "processing OTF scan : 03895 with reference scans dirs: 03894 and 03896\n",
      "\n",
      "processing OTF scan : 03897 with reference scans dirs: 03896 and 03898\n",
      "\n",
      "processing OTF scan : 03899 with reference scans dirs: 03898 and 03900\n",
      "\n",
      "processing OTF scan : 03901 with reference scans dirs: 03900 and 03902\n",
      "\n",
      "processing OTF scan : 03903 with reference scans dirs: 03902 and 03904\n",
      "Warning: problem in scan sequence. Expecting scan 3907, but loop at scan 3909.\n",
      "\n",
      "processing OTF scan : 03909 with reference scans dirs: 03908 and 03910\n",
      "\n",
      "processing OTF scan : 03911 with reference scans dirs: 03910 and 03912\n",
      "\n",
      "processing OTF scan : 03913 with reference scans dirs: 03912 and 03914\n",
      "\n",
      "processing OTF scan : 03915 with reference scans dirs: 03914 and 03916\n",
      "\n",
      "processing OTF scan : 03917 with reference scans dirs: 03916 and 03918\n",
      "\n",
      "processing OTF scan : 03919 with reference scans dirs: 03918 and 03920\n",
      "\n",
      "processing OTF scan : 03921 with reference scans dirs: 03920 and 03922\n",
      "\n",
      "processing OTF scan : 03923 with reference scans dirs: 03922 and 03924\n",
      "\n",
      "processing OTF scan : 03925 with reference scans dirs: 03924 and 03926\n",
      "\n",
      "processing OTF scan : 03927 with reference scans dirs: 03926 and 03928\n",
      "\n",
      "processing OTF scan : 03929 with reference scans dirs: 03928 and 03930\n",
      "\n",
      "processing OTF scan : 03931 with reference scans dirs: 03930 and 03932\n",
      "\n",
      "processing OTF scan : 03933 with reference scans dirs: 03932 and 03934\n",
      "\n",
      "processing OTF scan : 03935 with reference scans dirs: 03934 and 03936\n",
      "\n",
      "processing OTF scan : 03937 with reference scans dirs: 03936 and 03938\n",
      "\n",
      "processing OTF scan : 03939 with reference scans dirs: 03938 and 03940\n",
      "\n",
      "processing OTF scan : 03941 with reference scans dirs: 03940 and 03942\n",
      "\n",
      "processing OTF scan : 03943 with reference scans dirs: 03942 and 03944\n",
      "\n",
      "processing OTF scan : 03945 with reference scans dirs: 03944 and 03946\n",
      "\n",
      "processing OTF scan : 03947 with reference scans dirs: 03946 and 03948\n",
      "\n",
      "processing OTF scan : 03949 with reference scans dirs: 03948 and 03950\n",
      "\n",
      "processing OTF scan : 03951 with reference scans dirs: 03950 and 03952\n",
      "\n",
      "processing OTF scan : 03953 with reference scans dirs: 03952 and 03954\n",
      "\n",
      "processing OTF scan : 03955 with reference scans dirs: 03954 and 03956\n",
      "\n",
      "processing OTF scan : 03957 with reference scans dirs: 03956 and 03958\n",
      "\n",
      "processing OTF scan : 03959 with reference scans dirs: 03958 and 03960\n",
      "\n",
      "processing OTF scan : 03961 with reference scans dirs: 03960 and 03962\n",
      "\n",
      "processing OTF scan : 03963 with reference scans dirs: 03962 and 03964\n",
      "\n",
      "processing OTF scan : 03965 with reference scans dirs: 03964 and 03966\n",
      "\n",
      "processing OTF scan : 03967 with reference scans dirs: 03966 and 03968\n",
      "\n",
      "processing OTF scan : 03969 with reference scans dirs: 03968 and 03970\n",
      "\n",
      "processing OTF scan : 03971 with reference scans dirs: 03970 and 03972\n",
      "\n",
      "processing OTF scan : 03973 with reference scans dirs: 03972 and 03974\n",
      "\n",
      "processing OTF scan : 03975 with reference scans dirs: 03974 and 03976\n",
      "\n",
      "processing OTF scan : 03977 with reference scans dirs: 03976 and 03978\n",
      "\n",
      "processing OTF scan : 03979 with reference scans dirs: 03978 and 03980\n",
      "\n",
      "processing OTF scan : 03981 with reference scans dirs: 03980 and 03982\n",
      "\n",
      "processing OTF scan : 03983 with reference scans dirs: 03982 and 03984\n",
      "\n",
      "processing OTF scan : 03985 with reference scans dirs: 03984 and 03986\n",
      "\n",
      "processing OTF scan : 03987 with reference scans dirs: 03986 and 03988\n",
      "\n",
      "processing OTF scan : 03989 with reference scans dirs: 03988 and 03990\n",
      "\n",
      "processing OTF scan : 03991 with reference scans dirs: 03990 and 03992\n",
      "saved:  ./Data/processed/EtaCar_map1_0.7vp36_CII_2_3801_3993_v2_20200519.npz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib nbagg\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import ntpath\n",
    "from ALSFitter import arpls, nanarpls\n",
    "from STO2_v35 import *\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord, FK5\n",
    "from pylab import *\n",
    "from scipy import signal\n",
    "from scipy.stats import moment\n",
    "from scipy import interpolate\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pandas as pd\n",
    "import inspect\n",
    "\n",
    "print(inspect.stack()[0][1])\n",
    "plt.rcParams['axes.formatter.useoffset'] = False\n",
    "plt.rc(\"font\", size=5)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./jupyter_custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()\n",
    "\n",
    "\n",
    "def repUpdate(rep, irep, scan, obsid, obstype, verbose=False):\n",
    "    \"\"\"\n",
    "       updating the log (aka rep or report) of cleaned spike pixels\n",
    "       rep:   existing global report\n",
    "       irep:  new addendum to report (can be None!)\n",
    "       scan:  scan number\n",
    "       obsid: observation ID\n",
    "       obstype: observation type: hot, load, uref, dref, sig\n",
    "    \"\"\"\n",
    "    if irep!=None:\n",
    "        irep['scan'] = scan\n",
    "        irep['obsid'] = obsid\n",
    "        irep['type'] = obstype\n",
    "\n",
    "        if rep!=None: rep = np.vstack((rep,irep))\n",
    "        else: rep = irep\n",
    "            \n",
    "    if verbose: print('repUpdate:  obstype: %s pixels repaired'%(obstype))\n",
    "\n",
    "    # return the updated (or not) report\n",
    "    return rep\n",
    "\n",
    "\n",
    "# reading ordered sequence of data files\n",
    "def getFiles(stobsid, enobsid, cdirnum, path):\n",
    "    afiles = []\n",
    "    stobsid = np.squeeze(stobsid.copy())\n",
    "    enobsid = np.squeeze(enobsid.copy())\n",
    "    for i in range(stobsid, enobsid+1, 1):\n",
    "        aa = os.path.join(path,cdirnum,'OTF%s_%05i.fits'%(cdirnum,i))\n",
    "        # check if exists and append\n",
    "        if os.path.isfile(aa): afiles.append(aa)\n",
    "    return afiles\n",
    "\n",
    "\n",
    "def queryDir(path, cdirnum, search, gscan=0, lscan=99999):\n",
    "    \"\"\"\n",
    "    Function to query a STO-2 level 0.7 data directory for files matching the \"search\" string\n",
    "    Input:\n",
    "        path:    path to data directory\n",
    "        cdirnum: string of observation subdir number (with leading 0)\n",
    "        search:  search string (e.g.: '*OTF*.fits')\n",
    "        gscan:   integer minimum scan number (inclusive)\n",
    "        lscan:   integer maximum scan number (inclusive)\n",
    "    \"\"\"\n",
    "    #sname = os.path.join(sto2_path,cdirnum,'*OTF*.fits')\n",
    "    sname = os.path.join(path, cdirnum, search)\n",
    "    afiles = sorted(glob.glob(sname))\n",
    "    n_files = len(afiles)\n",
    "    asp = np.array([af.split('_')[1].split('.')[0] for af in afiles], dtype=np.float)\n",
    "    sel = np.where((asp>=gscan)&(asp<=lscan))\n",
    "    \n",
    "    return np.array(afiles)[sel]\n",
    "\n",
    "\n",
    "\n",
    "def resampleMask(mask, resp):\n",
    "#     imask = np.squeeze(mask[:resp*(mask.size//resp)])\n",
    "#     nmask = imask[::resp]\n",
    "#     for i in range(1,resp,1):\n",
    "#         nmask = np.bitwise_or(nmask, imask[i::resp])\n",
    "    \n",
    "#     return nmask\n",
    "    if mask.ndim==1:\n",
    "        imask = np.squeeze(mask[:resp*(mask.size//resp)])\n",
    "        nmask = imask[::resp]\n",
    "        for i in range(1,resp,1):\n",
    "            nmask = np.bitwise_or(nmask, imask[i::resp])\n",
    "        \n",
    "        return nmask\n",
    "    elif mask.ndim==2:\n",
    "        imask = np.squeeze(mask[:resp*(mask.shape[0]//resp),:])\n",
    "        nmask = imask[::resp]\n",
    "        for i in range(1,resp,1):\n",
    "            nmask = np.bitwise_or(nmask, imask[i::resp,:])\n",
    "        \n",
    "        return nmask\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "s_today = time.strftime(\"%Y%m%d\")\n",
    "now = time.strftime(\"%c\")\n",
    "print (\"Last execution: %s\"  % now )\n",
    "\n",
    "target = 'EtaCar'\n",
    "ctarget = 'Eta Carinae'\n",
    "\n",
    "\n",
    "# \n",
    "#\n",
    "# v_LSR = -50 km/s\n",
    "#\n",
    "# zero position\n",
    "# CDS position of EtaCar5:  ra=10 45 03.546 -59 41 03.95 \n",
    "#pos0 = SkyCoord('10h45m03.546s', '−59d41m03.95s', frame='icrs')\n",
    "# Eta Car: 286.10000,0.20000\n",
    "# Eta Car: 10h37m56.1s -58d14m24.9s\n",
    "#pos0 = SkyCoord(286.1*u.deg, 0.2*u.deg, frame='galactic').transform_to('fk5').transform_to(FK5(equinox='J2000'))\n",
    "pos0 = SkyCoord('10h45m00s', '−59d41m', frame='icrs')   # approximately from Matsuo et al. 2009\n",
    "l0 = pos0.galactic.l.degree\n",
    "b0 = pos0.galactic.b.degree\n",
    "ra0 = pos0.ra.deg\n",
    "dec0 = pos0.dec.deg\n",
    "print('Eta Car: %9.5f,%.5f'%(l0,b0))\n",
    "print('Eta Car: %s'%(pos0.to_string('hmsdms', precision=1)))\n",
    "    \n",
    "dversion = 'vp36'\n",
    "sto2_path = './Data/level0.7%s/'%(dversion)\n",
    "ofileroot = './Data/processed/EtaCar_map1_0.7%s'%(dversion)\n",
    "\n",
    "\n",
    "verbose = False\n",
    "verbose2 = False\n",
    "\n",
    "debug = False\n",
    "plotdebug = False\n",
    "# debug = False\n",
    "# plotdebug = False\n",
    "debug_stdir = 3859 # 3859\n",
    "\n",
    "cleanflag = False\n",
    "pcflag = False          # print the cleaning report\n",
    "boff = 2\n",
    "redflag = False\n",
    "saveflag = True\n",
    "if debug: saveflag = False\n",
    "add = ''\n",
    "tbadpix = np.zeros(0)\n",
    "rms1 = None\n",
    "rms1range = None\n",
    "rms2 = None\n",
    "rms2range = None\n",
    "norep = False       # force no repair (even if m1 or m2 in excel spreadsheet)\n",
    "\n",
    "Tcal = 300.\n",
    "\n",
    "# the Level 0.7v data have a new index for the CII line\n",
    "# select a line 0: NII_1, 1: NII_2, 2: CII_2 \n",
    "lin = 2\n",
    "trim = 0       # trimming the edges of the spectra\n",
    "rclip = 3      # replacing outer pixels with next value\n",
    "xlim  =[-50.,50.]\n",
    "ylim = [-30, 30.]\n",
    "anrange = [-99.0,49.] # range over which analysis should take place\n",
    "#anrange = [-120.0,65.] # range over which analysis should take place\n",
    "if (lin==0) | (lin==1): vrange = [-120., 65.] # limited velocity range for [NII]\n",
    "else: vrange = None\n",
    "rms1range = np.array([-70.,-30.])\n",
    "rms2range = np.array([0.0, 40.])\n",
    "resp = 4      # number of pixels to be resampled\n",
    "    \n",
    "# baseline fit exclusion region, e.g., presence of a line\n",
    "bxrange = np.array([-35, -8])   # km/s\n",
    "bxmode = 'slinear'   # from scipy.interpolate: ‘linear’, ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’, ‘previous’, ‘next’\n",
    "\n",
    "\n",
    "# derive correction factor for sideband\n",
    "# sideband gainratio R = g_usb / g_lsb => \n",
    "# fraction of from USB: G_usb = g_usb / (g_usb + g_lsb) = R / (1 + R) \n",
    "# for R = 1: G_USB = 0.5 OR Spectrum_USB = Spectrum_dsb / G_usb = 2.0 * Spectrum_dsb\n",
    "calibtype = 'SSB' # desired calibration: single sideband SSB or double sideband DSB\n",
    "gainratio = 1.0  # we do not know better\n",
    "if calibtype=='SSB':\n",
    "    sbcorr = (1 + gainratio) / gainratio\n",
    "else:\n",
    "    sbcorr = 1.0\n",
    "calibunit = 'K'\n",
    "caliblevel = 'T_A^*'\n",
    "\n",
    "\n",
    "# directory range for map:\n",
    "# the directories are alternating OTF and REF/HOT observations\n",
    "# the obs span dirs 6647 to 6757\n",
    "# the central position is around dirs 6680 and 6682\n",
    "stdir = 3801    # 3549\n",
    "endir = 3993  #3994    # 3563\n",
    "if debug: \n",
    "    stdir = debug_stdir\n",
    "    endir = stdir + 2\n",
    "\n",
    "mapdirs = np.arange(stdir,endir,2)\n",
    "#mapdirs = np.array([3981])         # for debugging only single strip\n",
    "#if mapdirs.size==1: saveflag=False  # for debugging no saving of processed data   \n",
    "\n",
    "# center of OTF strip is 19\n",
    "obsids = np.arange(2,54,1)\n",
    "\n",
    "if   lin==2: \n",
    "    cline = '[CII]'\n",
    "    cline2 = '[CII]'\n",
    "    add = '_CII_2'\n",
    "    badpix = np.zeros(0)\n",
    "elif lin==1: \n",
    "    cline = '[NII]'\n",
    "    cline2 = '[NII]2'\n",
    "    add = '_NII_2'\n",
    "    badpix = np.zeros(0)    # bad pixels more or less in all scans\n",
    "elif lin==0: \n",
    "    cline = '[NII]'\n",
    "    cline2 = '[NII]1'\n",
    "    add = '_NII_1'\n",
    "    badpix = np.zeros(0)    # bad pixels more or less in all scans\n",
    "else: add = ''\n",
    "    \n",
    "# if redflag:\n",
    "#     add += '_red'\n",
    "# else:\n",
    "#     add += '_full'\n",
    "\n",
    "\n",
    "print('Processing data for line: %s'%(add.replace('_',' ')))\n",
    "\n",
    "\n",
    "ofile = ofileroot+add+'_%i_%s.fits'%(stdir, s_today)\n",
    "nfile = ofileroot+add+'_%i_%s.npz'%(stdir, s_today)   # numpy archive file name\n",
    "\n",
    "\n",
    "# spectrum\n",
    "n_pix = 1024    # number of pixels per spectrum\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# get the predetermined info about the OTF scans\n",
    "print('reading excel data analysis sheet.')\n",
    "\n",
    "xfile = './Data/Ref_Lists/etaCar_reference_scans_list4.xlsx'\n",
    "with pd.ExcelFile(xfile) as xlsx:\n",
    "    sot = pd.read_excel(xlsx, 1, header=0, engine = 'xlrd')\n",
    "\n",
    "sotsz = sot.shape\n",
    "sot = sot.tail(sotsz[0]-1)\n",
    "colnames = sot.columns\n",
    "print(colnames)\n",
    "['drudir', '    dru', 'dhudir', '   dhu', 'dhucor', 'ohudir', '   ohu', 'orudir', '   oru', 'orucor', 'spdir', '  spec', ' spec2', 'orddir',\n",
    "   '   ord', 'ordcor', 'ohddir', '   ohd', 'dhddir', '   dhd', 'drddir', '   drd', 'des ref1', 'des ref2', 'brange1[0]', 'brange1[1]',\n",
    "   'brange2[0]', 'brange2[1]', 'order1', 'order2', 'despike']\n",
    "# handle is \"1\" for the scans to be processed\n",
    "so_spec  = np.array(sot['  spec'], dtype=np.int)\n",
    "so_spec2 = np.array(sot[' spec2'], dtype=np.int)\n",
    "so_spsc  = np.array(sot['spdir'], dtype=np.int)\n",
    "nrows = so_spsc.size\n",
    "print(so_spec.shape)\n",
    "\n",
    "# otf reference upper\n",
    "so_oru = np.array(sot['   oru'], dtype=np.int)\n",
    "so_orud = np.array(sot['orudir'], dtype=np.int)\n",
    "so_ohu = np.array(sot['   ohu'], dtype=np.int)\n",
    "so_ohud = np.array(sot['ohudir'], dtype=np.int)\n",
    "# designated reference upper\n",
    "so_dru = np.array(sot['    dru'], dtype=np.int)\n",
    "so_drud = np.array(sot['drudir'], dtype=np.int)\n",
    "so_dhu = np.array(sot['   dhu'], dtype=np.int)\n",
    "so_dhud = np.array(sot['dhudir'], dtype=np.int)\n",
    "# otf reference down\n",
    "so_ord = np.array(sot['   ord'], dtype=np.int)\n",
    "so_ordd = np.array(sot['orddir'], dtype=np.int)\n",
    "so_ohd = np.array(sot['   ohd'], dtype=np.int)\n",
    "so_ohdd = np.array(sot['ohddir'], dtype=np.int)\n",
    "# designated reference down\n",
    "so_drd = np.array(sot['   drd'], dtype=np.int)\n",
    "so_drdd = np.array(sot['drddir'], dtype=np.int)\n",
    "so_dhd = np.array(sot['   dhd'], dtype=np.int)\n",
    "so_dhdd = np.array(sot['dhddir'], dtype=np.int)\n",
    "\n",
    "so_case1 = np.array(sot['des ref1'], dtype=np.object)\n",
    "so_case2 = np.array(sot['des ref2'], dtype=np.object)\n",
    "\n",
    "so_br1 = np.zeros([nrows,2])\n",
    "so_br1[:,0] = np.array(sot['brange1[0]'], dtype=np.float)\n",
    "so_br1[:,1] = np.array(sot['brange1[1]'], dtype=np.float)\n",
    "so_bo1 = np.array(sot['order1'], dtype=np.float)\n",
    "so_br2 = np.zeros([nrows,2])\n",
    "so_br2[:,0] = np.array(sot['brange2[0]'], dtype=np.float)\n",
    "so_br2[:,1] = np.array(sot['brange2[1]'], dtype=np.float)\n",
    "so_bo2 = np.array(sot['order2'], dtype=np.float)\n",
    "\n",
    "so_order1 = np.array(sot['order1'], dtype=np.object)\n",
    "so_order2 = np.array(sot['order2'], dtype=np.object)\n",
    "\n",
    "so_despike = np.array(sot['despike'], dtype=np.object)\n",
    "\n",
    "\n",
    "badotfs = np.array([3905,3907])\n",
    "mapdirs = mapdirs[np.isin(mapdirs, badotfs, invert=True),]\n",
    "\n",
    "cnt = 0\n",
    "#if mapdirs.size==1: cnt = np.argwhere(so_spsc==mapdirs[0])[0][0]\n",
    "init = True\n",
    "print('mapdirs: ', mapdirs)\n",
    "if len(mapdirs)==1:\n",
    "    # set the counter so we can process only a single spectrum\n",
    "    cnt = np.squeeze(np.argwhere(so_spsc==mapdirs[0]))\n",
    "    debug = True\n",
    "\n",
    "for j in range(len(mapdirs)):\n",
    "        \n",
    "    #Signal\n",
    "    dirnum = mapdirs[j]\n",
    "    cdirnum = '%05i'%(dirnum)\n",
    "    chdirnum1 = '%05i'%(dirnum-1)\n",
    "    chdirnum2 = '%05i'%(dirnum+1)\n",
    "\n",
    "    repflag = np.zeros((3), dtype=int)\n",
    "    repmode = np.array(['org','org','org'])   # repmode: org: original, pre (previous HOT used), post (later HOT used), avg (average of pre and post HOT)\n",
    "    \n",
    "    if so_spsc[cnt]!=dirnum:   # e.g., scan 3905 is bad\n",
    "        print('Warning: problem in scan sequence. Expecting scan %i, but loop at scan %i.'%(so_spsc[cnt], dirnum))\n",
    "        cnt += 1\n",
    "        #continue\n",
    "        \n",
    "#     if dirnum in badotfs:\n",
    "#         print('Warning: Bad OTF scan. Skipping scan %i.'%(dirnum))\n",
    "#         continue\n",
    "    \n",
    "    print()\n",
    "    print('processing OTF scan : %s with reference scans dirs: %s and %s'%(cdirnum, chdirnum1, chdirnum2))\n",
    "    #sname = os.path.join(sto2_path,cdirnum,'*OTF*.fits')\n",
    "    #afiles = sorted(glob.glob(sname))\n",
    "    # we want only a reduced set of the OTF scans as pre-determined!\n",
    "    if debug: print('scan ids: ', cdirnum, so_spec[cnt], so_spec2[cnt])\n",
    "    #afiles = getFiles(so_spec[cnt], so_spec2[cnt], cdirnum, sto2_path)\n",
    "    afiles = getFiles(so_oru[cnt], so_ord[cnt], cdirnum, sto2_path)   # try to get more spectra!\n",
    "    n_files = len(afiles)\n",
    "    #for i in range(n_files): print(afiles[i])\n",
    "    \n",
    "    ###############################################################################################\n",
    "    # determine Tsys\n",
    "    # we get a Tsys from either end of the OTF strip.\n",
    "    # If a TSYS does not exist, we try to recover it by averaging the before \n",
    "    # and next Tsys from the same OTF strip end. There might also be some mitigation \n",
    "    # coming from the excel spreadsheet list read above.\n",
    "    \n",
    "    cTsys1 = 'Tsys 1'\n",
    "    t1rec = 0\n",
    "    Tsys1, tvv1, info1, rep1, t1mask = getTsysLine(chdirnum1, lin, ipath=sto2_path, verbose=verbose2, badpix=tbadpix, rclip=rclip, return_mask=True)\n",
    "    t1bad = np.all(t1mask>0)\n",
    "    if ((np.nanmean(Tsys1.value)==np.nanmax(Tsys1.value))|(np.nanmean(Tsys1.value)>3000.)|(np.nanmean(Tsys1.value)<1000.)):\n",
    "        if verbose: print(np.nanmax(Tsys1.value),np.nanmin(Tsys1.value), Tsys1.value[50:350])\n",
    "        # Tsys2 is not correct, try to recover\n",
    "        chdirnum1m = '%05i'%(dirnum-1-4)\n",
    "        Tsys11, tvv11, info11, rep11, t11mask = getTsysLine(chdirnum1m, lin, ipath=sto2_path, verbose=verbose2, badpix=tbadpix, rclip=rclip, return_mask=True)\n",
    "        chdirnum1m = '%05i'%(dirnum-1+4)\n",
    "        Tsys12, tvv12, info12, rep12, t12mask = getTsysLine(chdirnum1m, lin, ipath=sto2_path, verbose=verbose2, badpix=tbadpix, rclip=rclip, return_mask=True)\n",
    "        if np.nanmean(Tsys11.value)>100: fc11 = 1.\n",
    "        else: fc11 = 0.\n",
    "        if np.nanmean(Tsys12.value)>100: fc12 = 1.\n",
    "        else: fc12 = 0.\n",
    "        Tsys1 = (fc11*Tsys11 + fc12*Tsys12) / (fc11+fc12)\n",
    "        tvv1 = (fc11*tvv11 + fc12*tvv12) / (fc11+fc12)\n",
    "        t1mask = np.bitwise_or(t11mask, t12mask)\n",
    "        cTsys1 = 'Tsys 1 recov.'\n",
    "        t1rec = 1\n",
    "    Tsky = info1['Tsky']\n",
    "    Thot = info1['Thot']\n",
    "    \n",
    "    cTsys2 = 'Tsys 2'\n",
    "    t2rec = 0\n",
    "    Tsys2, tvv2, info2, rep2, t2mask = getTsysLine(chdirnum2, lin, ipath=sto2_path, verbose=verbose2, badpix=tbadpix, rclip=rclip, return_mask=True)\n",
    "    t2bad = np.all(t2mask>0)\n",
    "    if ((np.nanmean(Tsys2.value)==np.nanmax(Tsys2.value))|(np.nanmean(Tsys2.value)>3000.)|(np.nanmean(Tsys2.value)<1000.)):\n",
    "        # Tsys2 is not correct, try to recover\n",
    "        chdirnum2m = '%05i'%(dirnum+1-4)\n",
    "        Tsys21, tvv21, info21, rep21, t21mask = getTsysLine(chdirnum2m, lin, ipath=sto2_path, verbose=verbose2, badpix=tbadpix, rclip=rclip, return_mask=True)\n",
    "        chdirnum2m = '%05i'%(dirnum+1+4)\n",
    "        Tsys22, tvv22, info22, rep22, t22mask = getTsysLine(chdirnum2m, lin, ipath=sto2_path, verbose=verbose2, badpix=tbadpix, rclip=rclip, return_mask=True)\n",
    "        if np.nanmean(Tsys21.value)>100: fc21 = 1.\n",
    "        else: fc21 = 0.\n",
    "        if np.nanmean(Tsys22.value)>100: fc22 = 1.\n",
    "        else: fc22 = 0.\n",
    "        Tsys2 = (fc21*Tsys21 + fc22*Tsys22) / (fc21+fc22)\n",
    "        tvv2 = (fc21*tvv21 + fc22*tvv22) / (fc21+fc22)\n",
    "        t2mask = np.bitwise_or(t21mask, t22mask)\n",
    "        cTsys2 = 'Tsys 2 recov.'\n",
    "        t2rec = 1\n",
    "                \n",
    "    if debug: print('mean Tsys1: ', np.nanmean(Tsys1))\n",
    "    if debug: print('mean Tsys2: ', np.nanmean(Tsys2))\n",
    "    rep1 = 'o'\n",
    "    rep2 = 'o'\n",
    "    if np.isnan(np.nanmean(Tsys1)):\n",
    "        # print('Tsys1 is nan. replaced')\n",
    "        Tsys1 = Tsys2\n",
    "        rep1 = 'r'\n",
    "    if np.isnan(np.nanmean(Tsys2)):\n",
    "        #print('Tsys2 is nan. replaced')\n",
    "        Tsys2 = Tsys1\n",
    "        rep2 = 'r'\n",
    "    \n",
    "    # smooth the Tsys using arpls\n",
    "    Tsys1o = Tsys1.copy()\n",
    "    Tsys2o = Tsys2.copy()\n",
    "    Tsys1o.value[np.where(np.isnan(Tsys1o.value))] = 1E7\n",
    "    Tsys2o.value[np.where(np.isnan(Tsys2o.value))] = 1E7\n",
    "    Tsys1o.value[np.where(np.isinf(Tsys1o.value))] = 1E7\n",
    "    Tsys2o.value[np.where(np.isinf(Tsys2o.value))] = 1E7\n",
    "    Tsys1o.value[Tsys1o.value<1000.] = 1E7\n",
    "    Tsys2o.value[Tsys2o.value<1000.] = 1E7\n",
    "    # remove smaller spikes and smooth them\n",
    "    thresh = 50.\n",
    "    Tsys1o.value[np.where(np.abs((Tsys1o.value[1:]-Tsys1o.value[:-1]))>thresh)] = 1E7\n",
    "    Tsys2o.value[np.where(np.abs((Tsys2o.value[1:]-Tsys2o.value[:-1]))>thresh)] = 1E7\n",
    "    # the ratio has been tuned and lowered from 0.01 to 0.001 since it was causing spikes.\n",
    "    Tsys1, w1 = arplsw(Tsys1o.value, lam=2, ratio=0.001, itermax=30) * u.K\n",
    "    Tsys2, w2 = arplsw(Tsys2o.value, lam=2, ratio=0.001, itermax=30) * u.K\n",
    "\n",
    "    tostr = 'mean Tsys1 and Tsys2: %.1f K (%s)  %.1f K (%s)'%(np.nanmean(Tsys1.value), rep1, np.nanmean(Tsys2.value), rep2)\n",
    "    if debug: \n",
    "        print(tostr)\n",
    "        fig = plt.figure()\n",
    "        sp1 = plt.subplot()\n",
    "        pl1 = plt.plot(Tsys2o, color='lightgreen')\n",
    "        pl2 = plt.plot(Tsys1o, color='skyblue')\n",
    "        pl1 = plt.plot(Tsys2, color='green')\n",
    "        pl2 = plt.plot(Tsys1, color='blue')\n",
    "\n",
    " \n",
    "    ##############################################################################################    \n",
    "    # start processing the data\n",
    "    \n",
    "    ###### reference data (taken before OTF strip, also used for Tsys calculation):\n",
    "    # designated reference upper\n",
    "    drufile = os.path.join(sto2_path,'%05i/REF%05i_%05i.fits'%(so_drud[cnt],so_drud[cnt],so_dru[cnt]))\n",
    "    drul = 'rref'\n",
    "    if verbose2: print('designated ref: ', drufile)\n",
    "    druvv, dru, drumask, drupos, druh1 = readSTO2LineM(drufile, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    drubad = np.all(drumask>0)\n",
    "    druTint  = np.float(druh1['OBSTIME'])\n",
    "    druobsid = np.float(druh1['OBSID'])\n",
    "    drutime  = np.float(druh1['UNIXTIME'])\n",
    "    \n",
    "    # in case we have to repair the REF spectrum \n",
    "    if (so_case1[cnt]=='m1')&(norep==False):\n",
    "        # the designated ref 1 is missing !!!! \n",
    "        # => try to get the missing reference from old and future reference observations and average, in case they exist\n",
    "        chdirnum1m = '%05i'%(dirnum-1-4)\n",
    "        hun1 = os.path.join(sto2_path,chdirnum1m,'*REF*.fits')\n",
    "        druf1 = sorted(glob.glob(hun1))[0]\n",
    "        druvv1, dru1, dru1mask, drupos1, druh11 = readSTO2LineM(druf1, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "        if np.nanmean(dru1.value)>1E4: fc1 = 1.\n",
    "        else: fc1 =0.\n",
    "        chdirnum1m = '%05i'%(dirnum-1+4)\n",
    "        hun2 = os.path.join(sto2_path,chdirnum1m,'*REF*.fits')\n",
    "        druf2 = sorted(glob.glob(hun2))[0]\n",
    "        druvv2, dru2, dru2mask, drupos2, druh12 = readSTO2LineM(druf2, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "        if np.nanmean(dru2.value)>1E4: fc2 = 1.\n",
    "        else: fc2 =0.\n",
    "        if (fc1==0.)&(fc2==0.): print('Error. No reference observation available for scan %s'%(cdirnum))\n",
    "        dru = (fc1 * dru1 + fc2 * dru2) / (fc1 + fc2)\n",
    "        druvv = (fc1 * druvv1 + fc2 * druvv2) / (fc1 + fc2)\n",
    "        if (fc1==0.): \n",
    "            repmode = 'post'\n",
    "            drumask = dru2mask\n",
    "        if (fc2==0.): \n",
    "            repmode = 'pre'\n",
    "            drumask = dru1mask\n",
    "        else: \n",
    "            repmode = 'avg'\n",
    "            drumask = np.bitwise_or(dru1mask, dru2mask)\n",
    "        repflag[lin] = 1      # set flag since data were repaired\n",
    "        drul = 'rrefm'\n",
    "\n",
    "    \n",
    "    # designated hot upper\n",
    "    dhufile = os.path.join(sto2_path,'%05i/HOT%05i_%05i.fits'%(so_dhud[cnt],so_dhud[cnt],so_dhu[cnt]))\n",
    "    dhul = 'rhot'\n",
    "    dhuvv, dhu, dhumask, dhupos, dhuh1 = readSTO2LineM(dhufile, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    dhubad = np.all(dhumask>0)\n",
    "    dhuTint  = np.float(dhuh1['OBSTIME'])\n",
    "    dhuobsid = np.float(dhuh1['OBSID'])\n",
    "    dhutime  = np.float(dhuh1['UNIXTIME'])\n",
    "\n",
    "\n",
    "\n",
    "    # data in OTF strip scan\n",
    "    # OTF hot upper\n",
    "    ohufile = os.path.join(sto2_path,'%05i/HOT%05i_%05i.fits'%(so_ohud[cnt],so_ohud[cnt],so_ohu[cnt]))\n",
    "    ohul = 'ohot'\n",
    "    ohuvv, ohu, ohumask, ohupos, ohuh1 = readSTO2LineM(ohufile, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    ohubad = np.all(ohumask>0)\n",
    "    ohuTint  = np.float(ohuh1['OBSTIME'])\n",
    "    ohuobsid = np.float(ohuh1['OBSID'])\n",
    "    ohutime  = np.float(ohuh1['UNIXTIME'])\n",
    "    if ohu.mean().value <=1.: \n",
    "        ohu = dhu\n",
    "        if verbose: print('ALERT!!!!: otf hot 0, ohu, was replaced with ref hot, dhu')\n",
    "\n",
    "    \n",
    "    # otf reference upper (start of OTF scan)\n",
    "    orufile = os.path.join(sto2_path,'%05i/OTF%05i_%05i.fits'%(so_orud[cnt],so_orud[cnt],so_oru[cnt]))\n",
    "    orul = 'af%i'%(so_oru[cnt])\n",
    "    if verbose2: print('upper ref: ', orufile)\n",
    "    oruvv, oru, orumask, orupos, oruh1 = readSTO2LineM(orufile, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    orubad = np.all(orumask>0)\n",
    "    oruTint  = np.float(oruh1['OBSTIME'])\n",
    "    oruobsid = np.float(oruh1['OBSID'])\n",
    "    orutime  = np.float(oruh1['UNIXTIME'])\n",
    "\n",
    "\n",
    "    ##### OTF Signal Spectra \n",
    "    # get the OTF data files according to the spreadsheet, which lists the first and the last scan to be used\n",
    "    # hd1['SPECSTA4']=specsta4=='0x2000001' => spectrum is useful\n",
    "    if debug: print('scan ids: ', cdirnum, so_spec[cnt], so_spec2[cnt])\n",
    "    afiles = getFiles(so_spec[cnt], so_spec2[cnt], cdirnum, sto2_path)\n",
    "\n",
    "\n",
    "    # OTF reference down - ord (end of OTF strip)\n",
    "    ordfile = os.path.join(sto2_path,'%05i/OTF%05i_%05i.fits'%(so_ordd[cnt],so_ordd[cnt],so_ord[cnt]))\n",
    "    ordl = 'af%i'%(so_ord[cnt])\n",
    "    ordvv, ord, ordmask, ordpos, ordh1 = readSTO2LineM(ordfile, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    ordbad = np.all(ordmask>0)\n",
    "    ordTint  = np.float(ordh1['OBSTIME'])\n",
    "    ordobsid = np.float(ordh1['OBSID'])\n",
    "    ordtime  = np.float(ordh1['UNIXTIME'])\n",
    "\n",
    "    # OTF hot down - ohd\n",
    "    ohdfile = os.path.join(sto2_path,'%05i/HOT%05i_%05i.fits'%(so_ohdd[cnt],so_ohdd[cnt],so_ohd[cnt]))\n",
    "    ohdl = 'ohot2'\n",
    "    ohdvv, ohd, ohdmask, ohdpos, ohdh1 = readSTO2LineM(ohdfile, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    ohdbad = np.all(ohdmask>0)\n",
    "    ohdTint  = np.float(ohdh1['OBSTIME'])\n",
    "    ohdobsid = np.float(ohdh1['OBSID'])\n",
    "    ohdtime  = np.float(ohdh1['UNIXTIME'])\n",
    "\n",
    "    \n",
    "    \n",
    "    ##### reference data (taken after OTF strip, also used for Tsys calculation):\n",
    "    # designated reference down - drd\n",
    "    drdfile = os.path.join(sto2_path,'%05i/REF%05i_%05i.fits'%(so_drdd[cnt],so_drdd[cnt],so_drd[cnt]))\n",
    "    drdl = 'rref2'\n",
    "    drdvv, drd, drdmask, hdpos, drdh1 = readSTO2LineM(drdfile, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    drdbad = np.all(drdmask>0)\n",
    "    drdTint  = np.float(drdh1['OBSTIME'])\n",
    "    drdobsid = np.float(drdh1['OBSID'])\n",
    "    drdtime  = np.float(drdh1['UNIXTIME'])\n",
    "\n",
    "    if (so_case2[cnt]=='m2')&(norep==False):\n",
    "        if verbose: print('Case: m2')\n",
    "        # the designated ref 1 is missing !!!! \n",
    "        # => try to get the missing reference from old and future reference observations and average, in case they exist\n",
    "        chdirnum2m = '%05i'%(dirnum+1-4)\n",
    "        hdn1 = os.path.join(sto2_path,chdirnum2m,'*REF*.fits')\n",
    "        drdf1 = sorted(glob.glob(hdn1))[0]\n",
    "        drdvv1, drd1, drd1mask, drdpos1, drdh11 = readSTO2LineM(drdf1, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "        if np.nanmean(drd1.value)>1E4: fc12 = 1.\n",
    "        else: fc12 =0.\n",
    "        chdirnum2m = '%05i'%(dirnum+1+4)\n",
    "        hdn2 = os.path.join(sto2_path,chdirnum2m,'*REF*.fits')\n",
    "        drdf2 = sorted(glob.glob(hdn2))[0]\n",
    "        drdvv2, drd2, drd2mask, drdpos2, drdh12 = readSTO2LineM(drdf2, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "        if np.nanmean(drd2.value)>1E4: fc22 = 1.\n",
    "        else: fc22 =0.\n",
    "        if (fc12==0.)&(fc22==0.): print('Error. No reference observation available for scan %s'%(cdirnum))\n",
    "        drd = (fc12 * drd1 + fc22 * drd2) / (fc12 + fc22)\n",
    "        drdvv = (fc12 * drdvv1 + fc22 * drdvv2) / (fc12 + fc22)\n",
    "        if (fc12==0.): \n",
    "            repmode = 'post'\n",
    "            drdmask = drd2mask\n",
    "        if (fc22==0.): \n",
    "            repmode = 'pre'\n",
    "            drdmask = drd1mask\n",
    "        else: \n",
    "            repmode = 'avg'\n",
    "            drdmask = np.bitwise_or(drd1mask, drd2mask)\n",
    "        repflag[lin] = 1      # set flag since data were repaired\n",
    "        drdl = 'rref2m'\n",
    "\n",
    "\n",
    "    # designated hot down - dhd spectrum\n",
    "    dhdfile = os.path.join(sto2_path,'%05i/HOT%05i_%05i.fits'%(so_dhdd[cnt],so_dhdd[cnt],so_dhd[cnt]))\n",
    "    dhdl = 'rhot2'\n",
    "    dhdvv, dhd, dhdmask, dhdpos, dhdh1 = readSTO2LineM(dhdfile, lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    dhdbad = np.all(dhdmask>0)\n",
    "    dhdTint  = np.float(dhdh1['OBSTIME'])\n",
    "    dhdobsid = np.float(dhdh1['OBSID'])\n",
    "    dhdtime  = np.float(dhdh1['UNIXTIME'])\n",
    "\n",
    "    # done reading data\n",
    "    #########################################################################################################\n",
    "    \n",
    "\n",
    " \n",
    "    ##############################################################################################    \n",
    "    # Start processing the data\n",
    "    # (1) We are using the designated references and interpolate between start and end of OTF scan to \n",
    "    # mitigate linear drifts.\n",
    "    # (2) We are also using the HOT-measurement to further mitigate drifts.\n",
    "    #\n",
    "    # SIGi = <Tsys>t * (OTFi/<HOT>t - <REF>t/<HOT>t / (<REF>t/<HOT>t))\n",
    "    #\n",
    "    # <x>t: means time-weighted average of quantity x\n",
    "    # i:    i-th astronomical observation of OTF scan\n",
    "    # \n",
    "    # Now, how to correct for the remaining drift in the scans.\n",
    "    # (a) posible method is to use the data from the spreadsheet that includes a reference scan at the \n",
    "    # start and at the end of the OTF strip and the sequence of signal measurements. The references then \n",
    "    # can be baseline fitted and the baseline is corrected for in the raw spectra. These two corrected \n",
    "    # reference spectra can then be used to calculate <REF>t and used with the above equations to derive \n",
    "    # the final signal spectrum. Remaining baseline wiggles can then be removed with another (low-order)\n",
    "    # polynomial baseline fit.\n",
    "    \n",
    "    # define data record for each final spectrum that includes all the relevant information\n",
    "    # these records are then stacked and saved\n",
    "    oscan0 = {}\n",
    "    \n",
    "    # We have to create a correction derived from the baseline fit to the first and last spectrum in each OTF scan.\n",
    "    # Then, this baseline correction can be treated like the reference scans: \n",
    "    #     use the proper fractions from either end of the OTF scan and and removed the result from the scans\n",
    "    #\n",
    "    svv1, spec1, smask1, spos1, sh11 = readSTO2LineM(afiles[0],  lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    if debug: print('smask1: ', smask1.shape, lin, smask1[0:500])\n",
    "    rtime1  = np.float(sh11['UNIXTIME'])\n",
    "    svv2, spec2, smask2, spos2, sh12 = readSTO2LineM(afiles[-1], lin, verbose=verbose, rclip=rclip, badpix=badpix)\n",
    "    rtime2  = np.float(sh12['UNIXTIME'])\n",
    "    if debug: print('afiles[0]:  ', afiles[0])\n",
    "    if debug: print('afiles[-1]: ', afiles[-1])\n",
    "    \n",
    "    # 1. get the initial calibrated spectra\n",
    "    csp1 = (spec1/ohu - dru/dhu) / (dru/dhu) * Tsys1\n",
    "    csp2 = (spec2/ohd - drd/dhd) / (drd/dhd) * Tsys2\n",
    "    if debug: print('test: ', spec2[100:130], drd[100:130])\n",
    "    \n",
    "    # 2. resample the spectra\n",
    "    svv1h, csp1h = resampleSpectrum(svv1, csp1, resp)\n",
    "    svv2h, csp2h = resampleSpectrum(svv2, csp2, resp)\n",
    "    if debug: print('smask1: ', smask1.shape, smask1[10:30])\n",
    "    smask1h = resampleMask(smask1, resp)\n",
    "    smask2h = resampleMask(smask2, resp)\n",
    "    if debug: \n",
    "        print('smask1 resampled: ', smask1.shape, smask1[10:30])\n",
    "        print('smask2 resampled: ', smask2.shape, smask2[10:30])\n",
    "    \n",
    "    # 3. reduce the spectra to the analysis range\n",
    "    asel = np.where((svv1h.value>=anrange[0])&(svv1h.value<=anrange[1]))\n",
    "    svv1ha = svv1h[asel]\n",
    "    csp1ha = csp1h[asel]\n",
    "    svv2ha = svv2h[asel]\n",
    "    csp2ha = csp2h[asel]\n",
    "    smask1ha = smask1h[asel]\n",
    "    smask2ha = smask2h[asel]\n",
    "\n",
    "    \n",
    "    # 4. baseline fit to the spectra from # \n",
    "    # 4.0 Prepare data and polynomial fits\n",
    "    brange1 = so_br1[cnt,:]  \n",
    "    #print('brange1: ', brange1)\n",
    "    if np.any(np.isnan(brange1)): brange1 = [0.,0.]\n",
    "    if np.isfinite(so_order1[cnt]): order1 = so_order1[cnt]  \n",
    "    else: order1 = 19\n",
    "        \n",
    "    brange2 = so_br2[cnt,:]  \n",
    "    if np.any(np.isnan(brange2)): brange2 = [0.,0.]\n",
    "    if np.isfinite(so_order2[cnt]): order2 = so_order2[cnt]  \n",
    "    else: order2 = 19\n",
    "    \n",
    "    #### 4.1 baseline 1\n",
    "    #print('mask: ', smask1ha)\n",
    "    bsel1 = np.where(((svv1ha.value<brange1[0])|(svv1ha.value>brange1[1]))&(smask1ha==0)&np.isfinite(csp1ha))[0]\n",
    "    bsp1ha = csp1ha[bsel1].value\n",
    "    bvv1ha = svv1ha[bsel1].value\n",
    "    zu1 = np.polyfit(bvv1ha, bsp1ha, order1)\n",
    "    pu1 = np.poly1d(zu1)\n",
    "    bsp1 = csp1.value - pu1(svv1.value)              # baseline corrected full spectrum\n",
    "    bcor1 = pu1(svv1.value)                          # baseline correction only, for full spectrum\n",
    "    bcor1h = pu1(svv1h.value)                        # baseline correction only, for resampled spectrum\n",
    "    bcor1ha = pu1(svv1ha.value)                      # baseline correction only, for resampled reduced spectrum\n",
    "    bsp1s = smoothData(bsp1, fs=2000)*u.K      # basically this is the smooth contamination\n",
    "    \n",
    "    # now, we have to reverse de-calibrate the error signal in csp1habs\n",
    "    bsp1str = bsp1s / Tsys1 * (dru/dhu) * ohu\n",
    "    # control calculation\n",
    "    csp1c = ((spec1-bsp1str)/ohu - dru/dhu) / (dru/dhu) * Tsys1    # start of OTF scan\n",
    "    z1 = np.zeros(csp1.size)*u.K\n",
    "    ref1 = (((z1+bcor1*u.K)*(dru/dhu)/Tsys1)+(dru/dhu))*ohu\n",
    "    nsp1 = (spec1 - ref1) / ref1 * Tsys1      # this still might require the polyfit.\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### 4.2 baseline 2\n",
    "    bsel2 = np.where(((svv2ha.value<brange2[0])|(svv2ha.value>brange2[1]))&(smask2ha==0)&np.isfinite(csp2ha))[0]\n",
    "    bsp2ha = csp2ha[bsel2].value\n",
    "    bvv2ha = svv2ha[bsel2].value\n",
    "    zu2 = np.polyfit(bvv2ha, bsp2ha, order2)\n",
    "    pu2 = np.poly1d(zu2)\n",
    "    bcor2 = pu2(svv2.value)                          # baseline correction only, for full spectrum\n",
    "    bsp2 = csp2.value - pu2(svv2.value)              # baseline corrected full spectrum\n",
    "    bsp2s = smoothData(bsp2, fs=2000)*u.K      # basically this is the smooth contamination\n",
    "    \n",
    "    # now, we have to reverse de-calibrate the error signal in csp1habs\n",
    "    # this is the correction applied (subtracted) from the raw signal observation if used as reference\n",
    "    bsp2str = bsp2s / Tsys2 * (drd/dhd) * ohd\n",
    "    # control calculation\n",
    "    csp2c = ((spec2-bsp2str)/ohd - drd/dhd) / (drd/dhd) * Tsys2\n",
    "    z2 = np.zeros(csp2.size)*u.K\n",
    "    ref2 = (((z2+bcor2*u.K)*(drd/dhd)/Tsys2)+(drd/dhd))*ohd\n",
    "    nsp2 = (spec2 - ref2) / ref2 * Tsys2      # this still might require the polyfit.\n",
    "    \n",
    "    if plotdebug:\n",
    "        print('Plots of csp1, bsp1, and nsp1')\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        plt.plot(svv1, csp1, drawstyle='steps-post', color='blue', label='csp1')\n",
    "        plt.plot(svv1, bsp1, drawstyle='steps-post', color='green', label='bsp1')\n",
    "        plt.plot(svv1, nsp1, drawstyle='steps-post', color='red', label='nsp1')\n",
    "        plt.ylim(-8,15)\n",
    "        plt.legend()\n",
    "        print(spec1[100], ref1[100], nsp1[100])\n",
    "        \n",
    "        print('Plots of csp2, bsp2, and nsp2')\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        plt.plot(svv2, csp2, drawstyle='steps-post', color='blue', label='csp2')\n",
    "        plt.plot(svv2, bsp2, drawstyle='steps-post', color='green', label='bsp2')\n",
    "        plt.plot(svv2.value+0.01, nsp2, drawstyle='steps-post', color='red', label='nsp2')\n",
    "        plt.ylim(-8,15)\n",
    "        plt.legend()\n",
    "        print(spec2[100], ref2[100], nsp2[100])\n",
    "        \n",
    "        print('Plots of Tsys')\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        #plt.plot(svv, Tsys1, drawstyle='steps-post', color='blue', label='Tsys1')\n",
    "        plt.plot(Tsys2, drawstyle='steps-post', color='green', label='Tsys2')\n",
    "        plt.legend()\n",
    "        \n",
    "        print('Plots of bcor2')\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        #plt.plot(svv, Tsys1, drawstyle='steps-post', color='blue', label='Tsys1')\n",
    "        plt.plot(svv2ha, csp2ha, drawstyle='steps-post', color='blue', label='csp2ha')\n",
    "        #plt.plot(bvv2ha, bsp2ha, drawstyle='steps-post', color='green', label='bsp2ha')\n",
    "        plt.plot(svv2, bcor2, drawstyle='steps-post', color='red', label='bcor2')\n",
    "        plt.legend()\n",
    "        \n",
    "        print('Plots of end of OTF')\n",
    "        fig = plt.figure(figsize=(10,5))\n",
    "        plt.plot(drd, drawstyle='steps-post', color='blue', label='drd')\n",
    "        plt.plot(dhd, drawstyle='steps-post', color='red', label='dhd')\n",
    "        plt.plot(ohd, drawstyle='steps-post', color='green', label='ohd')\n",
    "        plt.plot(z2, drawstyle='steps-post', color='orange', label='z2')\n",
    "        plt.plot(bcor2, drawstyle='steps-post', color='purple', label='bcor2')\n",
    "        #plt.plot(svv2,Tsys2, drawstyle='steps-post', color='green', label='Tsys2')\n",
    "        plt.ylim(-8,15)\n",
    "        plt.legend()\n",
    "        \n",
    "        print('Now, the OTF spectra:')\n",
    "\n",
    "    \n",
    "    for afile in afiles:\n",
    "        svv, spec, smask, spos, sh1, srs = readSTO2LineM(afile, lin, verbose=verbose, rclip=rclip, badpix=badpix, retcl=True)\n",
    "        sbad = np.all(smask>0)\n",
    "        sobsid = np.float(sh1['OBSID'])\n",
    "        sTint  = np.float(sh1['OBSTIME'])\n",
    "        stime  = np.float(sh1['UNIXTIME'])\n",
    "        scan   = np.float(sh1['SCAN'])\n",
    "        specsta4 = sh1['SPECSTA4']\n",
    "        gl = spos.galactic.l.degree\n",
    "        gb = spos.galactic.b.degree\n",
    "        cmask = np.zeros([1024,16], dtype=np.int)  # mask for pixels\n",
    "        amask = np.zeros([16], dtype=np.int)       # mask for spectrum,\n",
    "\n",
    "        if ((sTint>0.)&(druTint>0.)&(drdTint>0.)&(dhuTint>0.)&(dhdTint>0.)&(ohuTint>0.)&(ohdTint>0.)&(specsta4=='0x2000001')):\n",
    "            # determine the reference spectrum to be applied to spectrum\n",
    "            # start: fraction is small (>= 0); end: fraction is large (<= 1)\n",
    "            if drutime<drdtime:\n",
    "                frac = (stime-drutime)/(drdtime-drutime)    # this is the fraction between the designated references\n",
    "            else: # some mitigation if reusing references\n",
    "                frac = (stime-dhutime)/(dhdtime-dhutime)\n",
    "            frac2 = (stime-rtime1)/(rtime2-rtime1)          # this is the fraction between the references\n",
    "            #print(rdobsid, obsid, ruobsid, frac)\n",
    "            # the calibration as of now is DSB !\n",
    "            Tsys = (1-frac2) * Tsys1 + frac2 * Tsys2\n",
    "            sref = (1-frac2) * ref1  + frac2 * ref2     \n",
    "            ################# signal spectrum #######################\n",
    "            sig = (sbcorr * (spec - sref) / sref * Tsys).value\n",
    "            \n",
    "#             # for simplicity here, we use only the spectrum mask since there are no rules yet \n",
    "#             # how to combine the other masks for the final spectrum\n",
    "#             print(smask.shape, smask.min(), smask.max())\n",
    "#             cmask[:,0] = smask\n",
    "            \n",
    "\n",
    "            \n",
    "            # added 3/4/2019\n",
    "            # perform a last baselinefit: \n",
    "            # 1: resample spectrum to reduce noise\n",
    "            # 2: check for nan's and infinite pixel values and \n",
    "            #    set them to the previous value or the next value depending on which one can be used (is finite)\n",
    "            # 3: perform the baseline fit\n",
    "            # 4: expand the fitted baseline to the full resolution by interpolating/extrapolating\n",
    "            # 5: save the results \n",
    "            vbrange  = np.array([-120, 65.]) # velocity range for baseline fit; ful range: ~-120 to ~65 km/s\n",
    "            vbrange  = np.array([-70, 45.])\n",
    "            vbrange  = np.array([-95, 45.])\n",
    "            rsel = np.where((svv.value>=vbrange[0])&(svv.value<=vbrange[1]))\n",
    "                        \n",
    "            # added 2/21/2020\n",
    "            ulimit = 30.\n",
    "            llimit = -15.\n",
    "            off = np.mean(np.percentile(sig, 60))\n",
    "            smaskr = np.squeeze(smask[rsel])\n",
    "            osel = np.where( (((sig[rsel]-off) > ulimit)|((sig[rsel]-off) < llimit)) & smaskr<1)\n",
    "            if debug: print(off, (sig[rsel]-off).min(), (sig[rsel]-off).max(), (sig[rsel]-off).mean(), np.median((sig[rsel]-off)), smask[osel].size)\n",
    "            (smask[rsel])[osel] = 32\n",
    "            if debug: print('smask: ', smask.shape, smask[osel].size)\n",
    "            \n",
    "            \n",
    "            svvr, sspr = resampleSpectrum(svv[rsel].value, sig[rsel], 4)\n",
    "            ssprb = np.squeeze(sspr.copy())\n",
    "            smsk = resampleMask(smask[rsel], 4)\n",
    "            sspr[smsk>0] = np.nan\n",
    "            ssprb[smsk>0] = np.nan\n",
    "            if debug: print(sspr.shape, smsk.shape, smask.shape)\n",
    "            #nsel = np.where(np.isnan(sspr)|np.isinf(sspr)|np.sum(smsk,axis=1)>0)\n",
    "            nsel = np.where(np.isnan(sspr)|np.isinf(sspr)|smsk>0)\n",
    "            if len(nsel)>0:\n",
    "                for km in nsel[0]:\n",
    "                    try:\n",
    "                        if np.isfinite(sspr[km+1]):\n",
    "                            sspr[km] = (sspr[km-1]+sspr[km+1])/2.\n",
    "                        else:\n",
    "                            sspr[km] = sspr[km-1]  \n",
    "                    except:\n",
    "                        sspr[km] = sspr[km-1]  \n",
    "            \n",
    "            # 2/20/2020\n",
    "            # we are removing the masked pixels and the nans and infs before fitting\n",
    "            # lam larger => smoother baseline\n",
    "            # ratio smaller => less neg. values\n",
    "            asspr = nanarpls(sspr, lam=1000, ratio=0.005)\n",
    "            bsspr = nanarpls(sspr, lam=1000, ratio=0.05)\n",
    "            csspr = nanarpls(sspr, lam=100,  ratio=0.05)\n",
    "            # repeat first baselinefit, but exclude the potential line region\n",
    "            # this might work or not!!!\n",
    "            sspr2 = sspr.copy()\n",
    "            bxsel = np.where((svvr>bxrange[0])&(svvr<bxrange[1]))\n",
    "            bxseln = np.where((svvr<bxrange[0])|(svvr>bxrange[1]))\n",
    "            sspr2[bxsel] = np.nan\n",
    "            dsspr = nanarpls(sspr2, lam=1000, ratio=0.005)\n",
    "            # fill in the baseline values using interpolation \n",
    "            dfr = interpolate.interp1d(svvr[bxseln], dsspr[bxseln], fill_value='extrapolate', kind=bxmode)\n",
    "            dsspr[bxsel] = dfr(svvr[bxsel])\n",
    "            #print(dfr)\n",
    "            #print(dsspr[bxsel])\n",
    "            \n",
    "            # test if we can expand the baseline to the full resolution.\n",
    "            af = interpolate.interp1d(svvr, asspr, fill_value='extrapolate', kind='cubic')\n",
    "            bf = interpolate.interp1d(svvr, bsspr, fill_value='extrapolate', kind='cubic')\n",
    "            cf = interpolate.interp1d(svvr, csspr, fill_value='extrapolate', kind='cubic')\n",
    "            # possible kinds: ‘linear’, ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’, ‘previous’, ‘next’\n",
    "            # set near the top in bxmode\n",
    "            df = interpolate.interp1d(svvr, dsspr, fill_value='extrapolate', kind=bxmode)\n",
    "            nrpx = svvr.size\n",
    "            # baseline for full spectrum\n",
    "            assps = af(svv)\n",
    "            bssps = bf(svv)\n",
    "            cssps = cf(svv)\n",
    "            dssps = df(svv)\n",
    "            \n",
    "            # replace the masked data in the signal array with the baseline fit data\n",
    "            sig[smask>1] = bssps[smask>1]\n",
    "            \n",
    "            # prepare arrays for storage\n",
    "            nres = 4\n",
    "            svvrs = np.zeros(256)\n",
    "            svvrs[0:nrpx] = svvr\n",
    "            ssprs = np.zeros(256)\n",
    "            ssprs[0:nrpx] = sspr\n",
    "            smskr = np.zeros((256,16), dtype=np.int)\n",
    "            smskr[0:nrpx,0] = smsk\n",
    "            # create arrays of the reduced (resampled) baseline fits\n",
    "            assprs = np.zeros(256)\n",
    "            assprs[0:nrpx] = asspr\n",
    "            bssprs = np.zeros(256)\n",
    "            bssprs[0:nrpx] = bsspr\n",
    "            cssprs = np.zeros(256)\n",
    "            cssprs[0:nrpx] = csspr\n",
    "            dssprs = np.zeros(256)\n",
    "            dssprs[0:nrpx] = dsspr\n",
    "\n",
    "            cmask[:,0:11] = np.vstack([smask, t1mask, t2mask, drumask, dhumask, ohumask, orumask, ordmask, ohdmask, drdmask, dhdmask]).swapaxes(0,1)\n",
    "            amask[0:11] = np.vstack([sbad, t1bad, t2bad, drubad, dhubad, ohubad, orubad, ordbad, ohdbad, drdbad, dhdbad]).swapaxes(0,1)\n",
    "            \n",
    "            \n",
    "            sig_wm = sig.copy()\n",
    "            sigc = sig.copy()# = smrepMask(svv, sig, smask)\n",
    "            \n",
    "            # calculate some rms values\n",
    "            if isinstance(rms1range,np.ndarray):\n",
    "                rms1sel = np.where((svv.value>=rms1range[0])&(svv.value<=rms1range[1]))\n",
    "                rms1vv = svv[rms1sel,]\n",
    "                rms1sig = np.squeeze(sig[rms1sel,])\n",
    "                rms1 = moment(rms1sig, moment=2, nan_policy='omit')\n",
    "            else:\n",
    "                rms1 = None\n",
    "            \n",
    "            # calculate some rms values\n",
    "            if isinstance(rms2range,np.ndarray):\n",
    "                rms2sel = np.where((svv.value>=rms2range[0])&(svv.value<=rms2range[1]))\n",
    "                rms2vv = svv[rms2sel,]\n",
    "                rms2sig = np.squeeze(sig[rms2sel,])\n",
    "                rms2 = moment(rms2sig, moment=2, nan_policy='omit')\n",
    "            else:\n",
    "                rms2 = None\n",
    "            \n",
    "            if debug:\n",
    "                print('Plotting spectrum: ', scan, sobsid)\n",
    "                dsel = np.where((svv.value>anrange[0])&(svv.value<anrange[1]))[0]\n",
    "                fig = plt.figure(figsize=(10,8))\n",
    "                sp1 = plt.subplot(4,1,1)\n",
    "                csig = np.squeeze(sig[rsel])\n",
    "                csig[smaskr>0] = off\n",
    "                pl1 = plt.plot(svv[rsel], csig-off, drawstyle='steps-post',label='sig',color='blue')\n",
    "                plt.xlim(anrange)\n",
    "                \n",
    "                sp1 = plt.subplot(4,1,2)\n",
    "                #pl1 = plt.plot(svv[rsel], smaskr, drawstyle='steps-post',label='smaskr',color='blue')\n",
    "                plt.xlim(anrange)\n",
    "                dsel = np.where((svv.value>anrange[0])&(svv.value<anrange[1]))[0]\n",
    "                pl2 = plt.plot(svv[dsel], sig[dsel], drawstyle='steps-post',label='sig',color='blue')\n",
    "                pl2 = plt.plot(svvr, sspr, drawstyle='steps-post',label='asspsr',color='blue')\n",
    "                #pl2 = plt.plot(svvr, ssprb, drawstyle='steps-post',label='asspsr',color='purple')\n",
    "                pl2 = plt.plot(svvr, asspr, drawstyle='steps-post',label='asspsr',color='orange')\n",
    "                pl2 = plt.plot(svvr, bsspr, drawstyle='steps-post',label='bsspsr',color='red')\n",
    "                pl2 = plt.plot(svvr, csspr, drawstyle='steps-post',label='csspsr',color='green')\n",
    "                pl2 = plt.plot(svvr, dsspr, drawstyle='steps-post',label='dsspsr',color='olive', linewidth=3.0)\n",
    "                \n",
    "                \n",
    "                sp1 = plt.subplot(4,1,3)                \n",
    "                dsel = np.where((svv.value>anrange[0])&(svv.value<anrange[1]))[0]\n",
    "                pl2 = plt.plot(svv[dsel], sig[dsel], drawstyle='steps-post',label='sig',color='blue')\n",
    "                pl2 = plt.plot(svv[dsel], assps[dsel], drawstyle='steps-post',label='assps',color='orange')\n",
    "                pl2 = plt.plot(svv[dsel], bssps[dsel], drawstyle='steps-post',label='bssps',color='red')\n",
    "                pl2 = plt.plot(svv[dsel], cssps[dsel], drawstyle='steps-post',label='cssps',color='green')\n",
    "                pl2 = plt.plot(svv[dsel], dssps[dsel], drawstyle='steps-post',label='dssps',color='olive', linewidth=3.0)\n",
    "                plt.xlim(anrange)\n",
    "                plt.legend()\n",
    "                \n",
    "                sp2 = plt.subplot(4,1,4)\n",
    "                dsel = np.where((svv.value>anrange[0])&(svv.value<anrange[1]))[0]\n",
    "                #pl2 = plt.plot(svv[dsel], sig[dsel], drawstyle='steps-post',label='sig',color='blue', alpha=0.3)\n",
    "                pl2 = plt.plot(svv[dsel], sig[dsel]-assps[dsel], drawstyle='steps-post',label='sig-assps',color='orange')\n",
    "                pl2 = plt.plot(svv[dsel], sig[dsel]-bssps[dsel], drawstyle='steps-post',label='sig-bssps',color='red')\n",
    "                pl2 = plt.plot(svv[dsel], sig[dsel]-cssps[dsel], drawstyle='steps-post',label='sig-cssps',color='green')\n",
    "                pl2 = plt.plot(svv[dsel], sig[dsel]-dssps[dsel], drawstyle='steps-post',label='sig-dssps',color='olive', linewidth=3.0)\n",
    "                plt.xlim(anrange)\n",
    "                plt.ylim([-10,30.])   # the fit/interpolation goes off the rails at the ends.\n",
    "                plt.legend()\n",
    "                \n",
    "                #print(spec[100], sref[100], sig[100])\n",
    "                #print(frac2, afile)\n",
    "                #print(svvrs[0:nrpx])\n",
    "                \n",
    "            zu1s = np.zeros(50)\n",
    "            zu1s[0:zu1.size] = zu1\n",
    "            zu2s = np.zeros(50)\n",
    "            zu2s[0:zu2.size] = zu2\n",
    "            # save all the data from up in a record, which will be concatenated to form the master record\n",
    "            sdat = np.array([(svv, sig, sigc, sref, ref1, ref2, frac, frac2, spec, dru, dhu, ohu, oru, ord, ohd, drd, dhd, smask, cmask, amask,\n",
    "                              scan, sobsid, druobsid, dhuobsid, ohuobsid, oruobsid, ordobsid, ohdobsid, drdobsid, dhdobsid, \n",
    "                              gl, gb, stime, sTint, lin, repflag, repmode, \n",
    "                              svvrs, ssprs, smskr, assprs, bssprs, cssprs, dssprs, assps, bssps, cssps, dssps, nrpx, nres, vbrange, \n",
    "                              bxmode, sbcorr, calibtype, gainratio, calibunit, caliblevel, \n",
    "                              csp1, csp2, bcor1, bcor2, zu1s, zu2s,\n",
    "                              Tsys, Tsys1, rep1, t1rec, Tsys2, rep2, t2rec, Thot, Tsky, rms1, rms1range, rms2, rms2range)], \n",
    "                              dtype=[\n",
    "                              ('vv', 'f8', 1024),('spec', 'f8', 1024),('specc', 'f8', 1024),('sref', 'f8', 1024),('ref1', 'f8', 1024),('ref2', 'f8', 1024), \n",
    "                              ('frac', 'f8'),('frac2', 'f8'),('spraw', 'f8', 1024),  \n",
    "                              ('dru', 'f8', 1024), ('dhu', 'f8', 1024), ('ohu', 'f8', 1024), ('oru', 'f8', 1024), ('ord', 'f8', 1024), ('ohd', 'f8', 1024), \n",
    "                              ('drd', 'f8', 1024), ('dhd', 'f8', 1024), ('mask','i4', 1024), ('cmask','i4', (1024,16)), ('amask','i4', 16),\n",
    "                              ('scan', 'f8'),('sobsid', 'f8'),('druobsid', 'f8'),('dhuobsid', 'f8'),\n",
    "                              ('ohuobsid', 'f8'),('oruobsid', 'f8'),('ordobsid', 'f8'),('ohdobsid', 'f8'),('drdobsid', 'f8'),('dhdobsid', 'f8'),\n",
    "                              ('gl','f8'),('gb','f8'),('time','f8'),('Tint','f8'),('line','i4'),('repflag','i4', 3),('repmode','S16', 3),\n",
    "                              ('vvr','f8', 256),('spr','f8',256),('mkr','f8',(256,16)),('aspr','f8',256),('bspr','f8',256),('cspr','f8',256),('dspr','f8',256),('asp','f8',1024),('bsp','f8',1024),('csp','f8',1024),('dsp','f8',1024),('nrpx','f8'),('nres','f8'),('vbrange','f8',2),\n",
    "                              ('bxmode', 'S16'),('sbcorr','f8'), ('calibtype', 'S3'), ('gainratio','f8'), ('calibunit', 'S16'), ('caliblevel', 'S16'),\n",
    "                              ('csp1','f8', 1024), ('csp2','f8', 1024), ('bcor1','f8', 1024), ('bcor2','f8', 1024), ('zu1','f8', 50), ('zu2','f8', 50), \n",
    "                              ('Tsys', 'f8', 1024),('Tsys1', 'f8', 1024),('Trep1', 'S1'),('Trec1', 'i4'),('Tsys2', 'f8', 1024),('Trep2', 'S1'),('Trec2', 'i4'),('Thot', 'f8'),('Tsky', 'f8'),\n",
    "                              ('rms1','f8'), ('rms1range','f8',2), ('rms2','f8'), ('rms2range','f8',2)])\n",
    "            # \n",
    "            # We should also save the data in the format of the original file with the raw spectrum\n",
    "            # replaced by the calibrated spectrum.\n",
    "            # we have the primary header with empyt data section\n",
    "            #  and the first extension with the table section. In latter is where the spectrum will end up.\n",
    "            hd0 = srs.getHeader0()\n",
    "            hd1 = srs.getHeader()\n",
    "            dd0 = srs.getRawData0()\n",
    "            dd1 = srs.getRawData()\n",
    "            cols = srs.getDataColumns()\n",
    "            \n",
    "            omask1 = smask + drumask + dhumask + ohumask + orumask + ordmask + ohdmask + drdmask + dhdmask\n",
    "            omask1[np.where(omask1>1)] = 1\n",
    "            tmask1 = t1mask + t2mask\n",
    "            sg = np.zeros([3,1024])\n",
    "            sg[lin,:]=np.squeeze(sig)\n",
    "            mcol1 = fits.Column(name='SPEC',  format='1024E', array=sg)\n",
    "            sr = np.zeros([3,1024])\n",
    "            sr[lin,:]=np.squeeze(sref)\n",
    "            mcol2 = fits.Column(name='RefSP', format='1024E', array=sr)\n",
    "            ts = np.zeros([3,1024])\n",
    "            ts[lin,:]=np.squeeze(Tsys)\n",
    "            mcol3 = fits.Column(name='TSYSs',  format='1024E', array=ts)\n",
    "            om = np.zeros([3,1024], dtype=np.int)\n",
    "            om[lin,:]=np.squeeze(omask1)\n",
    "            mcol4 = fits.Column(name='SMASK', format='1024J', array=om)\n",
    "            tm = np.zeros([3,1024], dtype=np.int)\n",
    "            tm[lin,:]=np.squeeze(tmask1)\n",
    "            mcol5 = fits.Column(name='TMASK', format='1024J', array=tm)\n",
    "            aas = np.zeros([3,1024])\n",
    "            aas[lin,:]=np.squeeze(assps)\n",
    "            mcol6a = fits.Column(name='BL_CORR1', format='1024E', array=aas)\n",
    "            bs = np.zeros([3,1024])\n",
    "            bs[lin,:]=np.squeeze(bssps)\n",
    "            mcol6b = fits.Column(name='BL_CORR2', format='1024E', array=bs)\n",
    "            cs = np.zeros([3,1024])\n",
    "            cs[lin,:]=np.squeeze(cssps)\n",
    "            mcol6c = fits.Column(name='BL_CORR3', format='1024E', array=cs)\n",
    "            bc1 = np.zeros([3,1024])\n",
    "            bc1[lin,:]=np.squeeze(bcor1)\n",
    "            mcol7 = fits.Column(name='BCOR1', format='1024E', array=bc1)\n",
    "            bc2 = np.zeros([3,1024])\n",
    "            bc2[lin,:]=np.squeeze(bcor2)\n",
    "            mcol8 = fits.Column(name='BCOR2', format='1024E', array=bc2)\n",
    "            sgc = np.zeros([3,1024])\n",
    "            sgc[lin,:]=np.squeeze(sigc)\n",
    "            mcol9 = fits.Column(name='SPECC',  format='1024E', array=sgc)\n",
    "            new_columns = cols + mcol1 + mcol2 + mcol3 + mcol4 + mcol5 + mcol6a + mcol6b + mcol6c + mcol7 + mcol8 + mcol9\n",
    "            new_hdu = fits.BinTableHDU.from_columns(new_columns)\n",
    "\n",
    "            # save data in new file (old: afile)\n",
    "            head, tail = ntpath.split(afile)\n",
    "            oroot = 'aapr%i/'%(lin)\n",
    "            if not os.path.isdir(sto2_path + oroot): os.mkdir(sto2_path + oroot)\n",
    "            if not os.path.isdir(sto2_path + oroot + '%s/'%(cdirnum)): os.mkdir(sto2_path + oroot + '%s/'%(cdirnum))\n",
    "            ofile = sto2_path + oroot + '%s/'%(cdirnum) + tail\n",
    "            fits.writeto(ofile, dd0, hd0, overwrite=True)\n",
    "            hd1['history'] = 'added calibrated data with updated mask; %s; V. Tolls'%(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            hd1['history'] = 'added baseline fit data'\n",
    "            hd1['history'] = 'added reference spectrum'\n",
    "            hd1['history'] = 'despiked pixel replaced with interpolated value.'\n",
    "            hd1['level1']  = ('VERSION %s'%(dversion), 'Applied on %s'%(datetime.datetime.now().strftime('%d %b %Y')))\n",
    "            fits.append(ofile, new_hdu.data, hd1)\n",
    "    \n",
    "            if init: \n",
    "                sdata = sdat\n",
    "                init = False\n",
    "            else: \n",
    "                sdata = np.vstack((sdata,sdat))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # final action at end of loop\n",
    "    cnt += 1\n",
    "    ##+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "    \n",
    "\n",
    "# create numpy file:\n",
    "# can be reloaded with: \n",
    "# npzfile = np.load(outfile)    # load file\n",
    "# print(npzfile.files)          # print variables\n",
    "# print(npzfile['variable'])    # retrieve variable\n",
    "if saveflag:\n",
    "    source = 'EtaCar2_OTF_L0.7-L1.0_processing_v4.ipynb'\n",
    "    nfile = ofileroot+add+'_%i_%i_v2_%s.npz'%(stdir, endir, s_today)   # numpy archive file name\n",
    "    np.savez(nfile, xfile=xfile, sdata=sdata, cline=cline, cline2=cline2, badotfs=badotfs, version='v2', source=source,\n",
    "             pos0=pos0, l0=l0, b0=b0, lin=lin, target=target, ctarget=ctarget)\n",
    "\n",
    "    print('saved: ', nfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
