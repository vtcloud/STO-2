{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Last execution: Tue May 19 12:55:12 2020\n",
      "sclip/eclip:  90 -140\n",
      "\n",
      "numpy mask data file:  ./Data//mask_analysis_level0.7vp36_compressed.npz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccf18a0da2d42faac3d3d2e03c08d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031737bd74ff4b2ca51f01eaf8882380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing scan : 03800 with 2 files\n",
      "processing scan : 03801 with 48 files\n",
      "processing scan : 03802 with 2 files\n",
      "processing scan : 03803 with 46 files\n",
      "processing scan : 03804 with 2 files\n",
      "processing scan : 03805 with 47 files\n",
      "processing scan : 03806 with 2 files\n",
      "processing scan : 03807 with 48 files\n",
      "processing scan : 03808 with 2 files\n",
      "processing scan : 03809 with 47 files\n",
      "processing scan : 03810 with 2 files\n",
      "processing scan : 03811 with 48 files\n",
      "processing scan : 03812 with 2 files\n",
      "processing scan : 03813 with 47 files\n",
      "processing scan : 03814 with 2 files\n",
      "processing scan : 03815 with 48 files\n",
      "processing scan : 03816 with 2 files\n",
      "processing scan : 03817 with 47 files\n",
      "processing scan : 03818 with 2 files\n",
      "processing scan : 03819 with 48 files\n",
      "processing scan : 03820 with 2 files\n",
      "processing scan : 03821 with 47 files\n",
      "processing scan : 03822 with 2 files\n",
      "processing scan : 03823 with 46 files\n",
      "processing scan : 03824 with 2 files\n",
      "processing scan : 03825 with 46 files\n",
      "processing scan : 03826 with 2 files\n",
      "processing scan : 03827 with 48 files\n",
      "processing scan : 03828 with 2 files\n",
      "processing scan : 03829 with 48 files\n",
      "processing scan : 03830 with 2 files\n",
      "processing scan : 03831 with 48 files\n",
      "processing scan : 03832 with 2 files\n",
      "processing scan : 03833 with 48 files\n",
      "processing scan : 03834 with 2 files\n",
      "processing scan : 03835 with 48 files\n",
      "processing scan : 03836 with 2 files\n",
      "processing scan : 03837 with 48 files\n",
      "processing scan : 03838 with 2 files\n",
      "processing scan : 03839 with 48 files\n",
      "processing scan : 03840 with 2 files\n",
      "processing scan : 03841 with 48 files\n",
      "processing scan : 03842 with 2 files\n",
      "processing scan : 03843 with 48 files\n",
      "processing scan : 03844 with 2 files\n",
      "processing scan : 03845 with 48 files\n",
      "processing scan : 03846 with 2 files\n",
      "processing scan : 03847 with 48 files\n",
      "processing scan : 03848 with 2 files\n",
      "processing scan : 03849 with 48 files\n",
      "processing scan : 03850 with 2 files\n",
      "processing scan : 03851 with 46 files\n",
      "processing scan : 03852 with 2 files\n",
      "processing scan : 03853 with 47 files\n",
      "processing scan : 03854 with 2 files\n",
      "processing scan : 03855 with 47 files\n",
      "processing scan : 03856 with 2 files\n",
      "processing scan : 03857 with 47 files\n",
      "processing scan : 03858 with 2 files\n",
      "processing scan : 03859 with 46 files\n",
      "processing scan : 03860 with 2 files\n",
      "processing scan : 03861 with 47 files\n",
      "processing scan : 03862 with 2 files\n",
      "processing scan : 03863 with 47 files\n",
      "processing scan : 03864 with 2 files\n",
      "processing scan : 03865 with 48 files\n",
      "processing scan : 03866 with 2 files\n",
      "processing scan : 03867 with 46 files\n",
      "processing scan : 03868 with 2 files\n",
      "processing scan : 03869 with 47 files\n",
      "processing scan : 03870 with 2 files\n",
      "processing scan : 03871 with 48 files\n",
      "processing scan : 03872 with 2 files\n",
      "processing scan : 03873 with 48 files\n",
      "processing scan : 03874 with 2 files\n",
      "processing scan : 03875 with 47 files\n",
      "processing scan : 03876 with 2 files\n",
      "processing scan : 03877 with 48 files\n",
      "processing scan : 03878 with 2 files\n",
      "processing scan : 03879 with 48 files\n",
      "processing scan : 03880 with 2 files\n",
      "processing scan : 03881 with 48 files\n",
      "processing scan : 03882 with 2 files\n",
      "processing scan : 03883 with 48 files\n",
      "processing scan : 03884 with 2 files\n",
      "processing scan : 03885 with 48 files\n",
      "processing scan : 03886 with 2 files\n",
      "processing scan : 03887 with 47 files\n",
      "processing scan : 03888 with 2 files\n",
      "processing scan : 03889 with 48 files\n",
      "processing scan : 03890 with 2 files\n",
      "processing scan : 03891 with 48 files\n",
      "processing scan : 03892 with 2 files\n",
      "processing scan : 03893 with 48 files\n",
      "processing scan : 03894 with 2 files\n",
      "processing scan : 03895 with 47 files\n",
      "processing scan : 03896 with 2 files\n",
      "processing scan : 03897 with 48 files\n",
      "processing scan : 03898 with 2 files\n",
      "processing scan : 03899 with 48 files\n",
      "processing scan : 03900 with 2 files\n",
      "processing scan : 03901 with 48 files\n",
      "processing scan : 03902 with 2 files\n",
      "processing scan : 03903 with 48 files\n",
      "processing scan : 03904 with 2 files\n",
      "processing scan : 03905 with 0 files\n",
      "processing scan : 03906 with 2 files\n",
      "processing scan : 03907 with 48 files\n",
      "processing scan : 03908 with 2 files\n",
      "processing scan : 03909 with 48 files\n",
      "processing scan : 03910 with 2 files\n",
      "processing scan : 03911 with 46 files\n",
      "processing scan : 03912 with 2 files\n",
      "processing scan : 03913 with 48 files\n",
      "processing scan : 03914 with 2 files\n",
      "processing scan : 03915 with 47 files\n",
      "processing scan : 03916 with 2 files\n",
      "processing scan : 03917 with 48 files\n",
      "processing scan : 03918 with 2 files\n",
      "processing scan : 03919 with 47 files\n",
      "processing scan : 03920 with 2 files\n",
      "processing scan : 03921 with 48 files\n",
      "processing scan : 03922 with 2 files\n",
      "processing scan : 03923 with 48 files\n",
      "processing scan : 03924 with 2 files\n",
      "processing scan : 03925 with 48 files\n",
      "processing scan : 03926 with 2 files\n",
      "processing scan : 03927 with 48 files\n",
      "processing scan : 03928 with 2 files\n",
      "processing scan : 03929 with 48 files\n",
      "processing scan : 03930 with 2 files\n",
      "processing scan : 03931 with 48 files\n",
      "processing scan : 03932 with 2 files\n",
      "processing scan : 03933 with 48 files\n",
      "processing scan : 03934 with 2 files\n",
      "processing scan : 03935 with 48 files\n",
      "processing scan : 03936 with 2 files\n",
      "processing scan : 03937 with 48 files\n",
      "processing scan : 03938 with 2 files\n",
      "processing scan : 03939 with 48 files\n",
      "processing scan : 03940 with 2 files\n",
      "processing scan : 03941 with 48 files\n",
      "processing scan : 03942 with 2 files\n",
      "processing scan : 03943 with 49 files\n",
      "processing scan : 03944 with 2 files\n",
      "processing scan : 03945 with 48 files\n",
      "processing scan : 03946 with 2 files\n",
      "processing scan : 03947 with 48 files\n",
      "processing scan : 03948 with 2 files\n",
      "processing scan : 03949 with 48 files\n",
      "processing scan : 03950 with 2 files\n",
      "processing scan : 03951 with 48 files\n",
      "processing scan : 03952 with 2 files\n",
      "processing scan : 03953 with 48 files\n",
      "processing scan : 03954 with 2 files\n",
      "processing scan : 03955 with 49 files\n",
      "processing scan : 03956 with 2 files\n",
      "processing scan : 03957 with 48 files\n",
      "processing scan : 03958 with 2 files\n",
      "processing scan : 03959 with 48 files\n",
      "processing scan : 03960 with 2 files\n",
      "processing scan : 03961 with 47 files\n",
      "processing scan : 03962 with 2 files\n",
      "processing scan : 03963 with 48 files\n",
      "processing scan : 03964 with 2 files\n",
      "processing scan : 03965 with 45 files\n",
      "processing scan : 03966 with 2 files\n",
      "processing scan : 03967 with 47 files\n",
      "processing scan : 03968 with 2 files\n",
      "processing scan : 03969 with 48 files\n",
      "processing scan : 03970 with 2 files\n",
      "processing scan : 03971 with 46 files\n",
      "processing scan : 03972 with 2 files\n",
      "processing scan : 03973 with 47 files\n",
      "processing scan : 03974 with 2 files\n",
      "processing scan : 03975 with 48 files\n",
      "processing scan : 03976 with 2 files\n",
      "processing scan : 03977 with 48 files\n",
      "processing scan : 03978 with 2 files\n",
      "processing scan : 03979 with 47 files\n",
      "processing scan : 03980 with 2 files\n",
      "processing scan : 03981 with 46 files\n",
      "processing scan : 03982 with 2 files\n",
      "processing scan : 03983 with 47 files\n",
      "processing scan : 03984 with 2 files\n",
      "processing scan : 03985 with 48 files\n",
      "processing scan : 03986 with 2 files\n",
      "processing scan : 03987 with 48 files\n",
      "processing scan : 03988 with 2 files\n",
      "processing scan : 03989 with 48 files\n",
      "processing scan : 03990 with 2 files\n",
      "processing scan : 03991 with 48 files\n",
      "processing scan : 03992 with 2 files\n",
      "processing scan : 03993 with 48 files\n",
      "processing scan : 03994 with 2 files\n",
      "processing scan : 03995 with 47 files\n",
      "processing scan : 03996 with 0 files\n",
      "processing scan : 03997 with 0 files\n",
      "processing scan : 03998 with 0 files\n",
      "processing scan : 03999 with 0 files\n",
      "\n",
      "created:  ./Data//mask_analysis_level0.7vp36_compressed.npz\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib nbagg\n",
    "\n",
    "\"\"\"\n",
    "In order for the notebook to run properly, the STO-2 input data should be in directory\n",
    "\n",
    "    sto2_ipath      e.g.,: = './Data/level0.7/'\n",
    "\n",
    "This directory should contain subdirectories named \"xxxxx\" like \"03800\", \"03801\", ....\n",
    "The actual data files are in these subdirectories:\n",
    "E.g. in: \n",
    " ./03800/\n",
    "   HOT03800_08190.fits\n",
    "   REF03800_08191.fits\n",
    " ./03801/\n",
    "   HOT03801_08192.fits\n",
    "   HOT03801_08239.fits\n",
    "   OTF03801_08193.fits\n",
    "   OTF03801_08194.fits\n",
    "   .\n",
    "   .\n",
    "   .\n",
    "   .\n",
    "\n",
    "Look for more comments in the code explaining what is being done.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "import datetime\n",
    "from STO2_v35 import *\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord, FK5\n",
    "from astropy.utils.console import ProgressBar\n",
    "from pylab import *\n",
    "from scipy import signal\n",
    "from scipy.signal import medfilt\n",
    "from scipy.interpolate import interp1d\n",
    "#from loess_1d import loess_1d\n",
    "from ALSFitter import *\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "plt.rcParams['axes.formatter.useoffset'] = False\n",
    "plt.rc(\"font\", size=5)\n",
    "#warnings.simplefilter('ignore', 'VerifyWarning')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./jupyter_custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()\n",
    "\n",
    "\n",
    "import time\n",
    "s_today = time.strftime(\"%Y%m%d\")\n",
    "now = time.strftime(\"%c\")\n",
    "print (\"Last execution: %s\"  % now )\n",
    "\n",
    "\n",
    "\n",
    "nbfile = 'STO2/EtaCar/EtaCar2_despike_OTF_3801_L0.7_2Steps.ipynb'\n",
    "nbversion = '1.0g'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "# some adjustments can be made here!!!\n",
    "\n",
    "\n",
    "olevel = 'level0.7vp36'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "badpix = None\n",
    "badpix = [479,480,481,482,483,484,485,486,487,488,489,490,491]  # forced bad pixels for all lines!\n",
    "thresh = 12000.\n",
    "near = 2        # mask also the next near=2 pixels on either side\n",
    "npzflag = True  # flag indicating to create a numpy data file containing the despiked data\n",
    "verbose = False\n",
    "verbose1 = False\n",
    "verbose2 = False    # get information from the mask processing\n",
    "lin = 1   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# number of channels at end of spectrum replaced with value of n_rclip+1 spectral element\n",
    "n_rclip = 2\n",
    "# number of wing pixels corrected\n",
    "nwpix = 1\n",
    "# window width of median filter for determining bad pixel \n",
    "#  - if too small, detection might fail\n",
    "#  - if too large, not sensitive if curvy bandpass\n",
    "ww = 21\n",
    "# borderpix (not used!)\n",
    "borderpix = 5\n",
    "rmethod = 'nan'  # can be 'nan' or 'replace'\n",
    "\n",
    "tbad = np.array([484,485,486,487,488])\n",
    "tbad = None\n",
    "niirange = np.array([130,929], dtype=int)\n",
    "\n",
    "\n",
    "sto2_ipath = './Data/level0.7/'     # STO-2 input files from Arizona\n",
    "sto2_opath_root = './Data/'         # new cleaned files\n",
    "sto2_opath = './Data/'+olevel       # new cleaned files\n",
    "\n",
    "\n",
    "# directory range for Eta Carinae observation\n",
    "# the directories are alternating OTF and REF/HOT observations\n",
    "stdir = 3800   # directory number for starting the processing (should be REF/HOT observations)\n",
    "endir = 4000   # last directory processed (should be REF/HOT observations)\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "# create output path if not exist\n",
    "if not os.path.isdir(sto2_opath): os.mkdir(os.path.join(sto2_opath))  \n",
    "\n",
    "# open a text file to log missing spectra (spectra are nan's, zeros, etc)\n",
    "mlog_file = sto2_opath+'/aa_%s_missing_log.txt'%(olevel)\n",
    "mlogf = open(mlog_file, 'w', encoding='utf-8')\n",
    "mlogf.write(' Scan ObsID Line')\n",
    "\n",
    "def mlogprint(ostr):\n",
    "    mlogf.write(ostr+'\\n')\n",
    "\n",
    "    \n",
    "mapdirs = np.arange(stdir,endir,1)\n",
    "#mapdirs = np.array([3801])\n",
    "\n",
    "if   lin==2: \n",
    "    add = '_CII_2'\n",
    "    sclipl=5\n",
    "    eclipl=-5\n",
    "elif lin==1: \n",
    "    add = '_NII_2'\n",
    "    sclipl=90\n",
    "    eclipl=-140\n",
    "elif lin==0: \n",
    "    add = '_NII_1'\n",
    "    sclipl=90\n",
    "    eclipl=-140\n",
    "else: add = ''\n",
    "    \n",
    "print('sclip/eclip: ', sclipl, eclipl)\n",
    "print()\n",
    "\n",
    "if npzflag: print('numpy mask data file: ', sto2_opath_root+'/mask_analysis_%s_compressed.npz'%(olevel))\n",
    "\n",
    "\n",
    "# get the number of files, n_files, to be processed and the number of pixels, n_pix, in a spectrum assuming\n",
    "# all spectra have the same length\n",
    "ffilter = '*.fits'\n",
    "n_files = 0\n",
    "get = 0\n",
    "for j in ProgressBar(range(len(mapdirs)), ipython_widget=True):\n",
    "\n",
    "    dirnum = mapdirs[j]\n",
    "    cdirnum = '%05i'%(dirnum)\n",
    "    pdirnum = '/%05i/'%(dirnum)\n",
    "    \n",
    "    sname = os.path.join(sto2_ipath,cdirnum,ffilter)\n",
    "    afiles = sorted(glob.glob(sname))\n",
    "    n_afiles = len(afiles)\n",
    "    n_files += n_afiles\n",
    "    if (j==get)&(n_afiles>0):\n",
    "        with fits.open(afiles[0]) as hl:\n",
    "            hd0 = hl[0].header\n",
    "            dd0 = hl[0].data\n",
    "            hd1 = hl[1].header\n",
    "            dd1 = hl[1].data\n",
    "\n",
    "            dat = dd1['DATA']\n",
    "            n_pix = dat.shape[1]\n",
    "    elif (j==get)&(n_afiles==0):\n",
    "        get += 1\n",
    "\n",
    "\n",
    "# if desired, prepare numpy file variables\n",
    "if npzflag:\n",
    "    idat = np.zeros((n_files,3,n_pix))\n",
    "    # image of associated masks\n",
    "    imsk = np.zeros((n_files,3,n_pix), dtype=np.int)\n",
    "    # counter for spectra read\n",
    "    ivv = np.zeros((n_files,3,n_pix))\n",
    "    icd = np.zeros((n_files,3))     # for CDELT1 per line\n",
    "    icv = np.zeros((n_files))       # for CRVAL1 (same for all lines)\n",
    "    icp = np.zeros((n_files,3))     # for CRPIX1 per line\n",
    "    cnt = 0  \n",
    "    obsids = np.zeros((n_files))\n",
    "    scans  = np.zeros((n_files))\n",
    "    ifil  = np.ndarray((n_files), dtype=np.object)\n",
    "\n",
    "\n",
    "\n",
    "for j in ProgressBar(range(len(mapdirs)), ipython_widget=True):\n",
    "\n",
    "    dirnum = mapdirs[j]\n",
    "    cdirnum = '%05i'%(dirnum)\n",
    "\n",
    "    sname = os.path.join(sto2_ipath,cdirnum,'*.fits')\n",
    "    odir = os.path.join(sto2_opath,cdirnum)\n",
    "    afiles = sorted(glob.glob(sname))\n",
    "    n_files = len(afiles)\n",
    "    print('processing scan : %s with %i files'%(cdirnum, n_files))\n",
    "    \n",
    "    for k in range(0,n_files):\n",
    "        ifile = afiles[k]\n",
    "        if verbose1: print('   ', ifile)\n",
    "        ofile = ifile.replace('level0.7',olevel)\n",
    "        if not os.path.isdir(odir): os.mkdir(odir)\n",
    "        \n",
    "        with fits.open(ifile) as hl:\n",
    "            hd0 = hl[0].header\n",
    "            dd0 = hl[0].data\n",
    "            hd1 = hl[1].header\n",
    "            dd1 = hl[1].data\n",
    "\n",
    "            dat = dd1['DATA']\n",
    "            tint = np.float(hd1['OBSTIME'])\n",
    "            tscan  = np.float(hd1['SCAN'])\n",
    "            tobsid = np.float(hd1['OBSID'])\n",
    "            ttype = hd1['TYPE']\n",
    "            cols = hl[1].columns\n",
    "            nrows = hl[1].data.shape[0] + 2\n",
    "\n",
    "            nlin, npix = dat.shape\n",
    "\n",
    "            mask = np.zeros([nlin, npix], dtype=np.int)\n",
    "            # If the notebook crashes here, execute the cells below first to load the missing functions.\n",
    "            mask = addHeaderBadPixels(hd1['COMMENT'], mask)\n",
    "                        \n",
    "            # bit 1 => set value 1 of mask:  all spectral data values are NaNs or zeros\n",
    "            # bit 2 => set value 2 of mask:  major (previously identified) spikes\n",
    "            # bit 3 => set value 4 to mask:  new despiking, e.g., residuals of transmission LO interference or so\n",
    "            # bit 4 => set value 8 to mask:  end of spectrum outliers clipped spectral elements\n",
    "            \n",
    "            for i in range(nlin):\n",
    "                if np.all(np.isnan(dat[i,:])): np.bitwise_or(mask[i,:], 1)   # spectra all nans\n",
    "                if np.all(dat[i,:]==0.0):      np.bitwise_or(mask[i,:], 1)   # spectra all zero\n",
    "                                       \n",
    "                spec = np.squeeze(dat[i,:])\n",
    "                smask = np.squeeze(mask[i,:])\n",
    "                \n",
    "                if (np.nanmin(spec) == np.nanmax(spec))|(np.all(np.isnan(spec))):\n",
    "                    # this is to log files with missing data\n",
    "                    ostr = '%05i %05i %4i %s'%(tscan, tobsid, i, ttype)\n",
    "                    mlogprint(ostr)\n",
    "                \n",
    "                if lin==2:\n",
    "                    ospec, omask = repSpike1D(spec/tint, smask, sclip=sclipl, eclip=eclipl, near=1, verbose=verbose2, badpix=badpix, thresh=thresh)\n",
    "                else:\n",
    "                    ospec, omask = repSpike1D(spec/tint, smask, sclip=sclipl, eclip=eclipl, near=1, verbose=verbose2, badpix=badpix, thresh=thresh)\n",
    "                \n",
    "                # we have to reverse the division by the integration time\n",
    "                dat[i,:]  = ospec*tint\n",
    "                mask[i,:] = omask\n",
    "\n",
    "            dd1['DATA'] = dat\n",
    "\n",
    "            # append the mask to the fits table (is there a better way?)\n",
    "            mcol = fits.Column(name='MASK', format='1024J', array=mask)\n",
    "            new_columns = hl[1].columns + mcol\n",
    "            new_hdu = fits.BinTableHDU.from_columns(new_columns)\n",
    "\n",
    "\n",
    "            # test if output directory exists, if not, create\n",
    "            odir = os.path.join(sto2_ipath,cdirnum)\n",
    "            odir = odir.replace('level0.7',olevel)\n",
    "            if not os.path.isdir(odir):\n",
    "                #create the output directory\n",
    "                os.mkdir(os.path.join(odir))\n",
    "\n",
    "            # save data\n",
    "            fits.writeto(ofile, dd0, hd0, overwrite=True)\n",
    "            hd1['history'] = '0.7v added mask with despike info; %s; user_xxx'%(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "            hd1['history'] = 'despike threshold: %f'%(thresh)\n",
    "            hd1['history'] = 'adjacent pixels: %i'%(near)\n",
    "            hd1['history'] = 'despiked pixel replaced with interpolated value.'\n",
    "            hd1['level0']  = ('VERSION 0.7v', 'Applied on %s'%(datetime.datetime.now().strftime('%d %b %Y')))\n",
    "            fits.append(ofile, new_hdu.data, hd1)\n",
    "\n",
    "            \n",
    "            # create the optional numpy array\n",
    "            if npzflag:\n",
    "                dd1 = new_hdu.data\n",
    "                ifil[cnt] = ifile\n",
    "                dat = dd1['DATA']\n",
    "                idat[cnt,:,:] = dat\n",
    "                mask = dd1['MASK']\n",
    "                imsk[cnt,:,:] = mask\n",
    "                icd[cnt,:] = dd1['CDELT1']\n",
    "                icv[cnt] = hd1['CRVAL1']\n",
    "                icp[cnt,:] = dd1['CRPIX1']\n",
    "                ivv[cnt,lin,:] = (np.float(hd1['CRVAL1']) + (1 + np.arange(n_pix) - dd1['CRPIX1'][lin]) * dd1['CDELT1'][lin])\n",
    "                tint = np.float(hd1['OBSTIME'])\n",
    "                tscan  = np.float(hd1['SCAN'])\n",
    "                scans[cnt] = tscan\n",
    "                tobsid = np.float(hd1['OBSID'])\n",
    "                obsids[cnt] = tobsid\n",
    "                ttype = hd1['TYPE']\n",
    "                cnt += 1\n",
    "\n",
    "\n",
    "if npzflag:\n",
    "                \n",
    "    idat = idat[:cnt,:,:]\n",
    "    imsk = imsk[:cnt,:,:]\n",
    "    cnow = time.strftime(\"%c\")\n",
    "\n",
    "\n",
    "    dfile = sto2_opath_root+'/mask_analysis_%s_compressed.npz'%(olevel)\n",
    "    np.savez_compressed(dfile, idat=idat, imsk=imsk, icd=icd, icv=icv, icp=icp, ivv=ivv, scans=scans, \n",
    "                        obsids=obsids, cnt=cnt, filen = ifil, olevel=olevel, nbversion=nbversion,\n",
    "                        nbfile=nbfile, created=cnow, \n",
    "                        sto2_ipath=sto2_ipath)\n",
    "\n",
    "    print('created: ', dfile)\n",
    "\n",
    "            \n",
    "            \n",
    "mlogf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning procedure\n",
    "\n",
    "as of 8/26/2019\n",
    "\n",
    "\n",
    "However, the primary function file is in STO2_v35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading functions ...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from scipy import interpolate\n",
    "\n",
    "print('loading functions ...')\n",
    "\n",
    "def repSpike1D(ispec1, imask1, sclip=0, eclip=0, thresh = 10000, bit2flag=False, verbose=False):\n",
    "    \"\"\"\n",
    "    This function is still experimental, hence the many print statements for debugging.\n",
    "    \n",
    "    This is the latest cleaning function, based on a several step cleaning procedure.\n",
    "    The first step removes and replaces the large spikes and tries to interpolate the missing\n",
    "    values. There is an option for replacing the first sclip pixels with the value of pixel[sclip] \n",
    "    and the last eclip pixels with the value of pixel[eclip]. These ranges were almost impossible \n",
    "    to clean and repair for [NII], and this methods seems to be the best option since the data are \n",
    "    useless in any case. \n",
    "    The second step removes smaller spikes that have an amplitude larger than thresh compared \n",
    "    to the adjacent pixels. Here are 2 option, using the median filtered difference or the ALS difference\n",
    "    of old minus filtered spectrum? Only positive spikes are removed. Only median filer used right now.\n",
    "    \n",
    "    Compare to subroutine setMask() below for changes in flagging:\n",
    "    Meaning of mask bits (might change slightly in future by adding new values, 16 bits available):    \n",
    "        bit 0 => add 1 to mask:  all spectral data values are NaNs or zeros\n",
    "        bit 1 => add 2 to mask:  spikes listed in comment area of raw (level 0.5+) files.\n",
    "        bit 2 => add 4 to mask:  new despiking, e.g., residuals of transmission LO interference or so\n",
    "        bit 3 => add 8 to mask:  end of spectrum outliers clipped spectral elements\n",
    "    \n",
    "    Inputs:\n",
    "        ispec1:      \"dirty\" spectrum\n",
    "        imask1:      initial mask, most likely empty\n",
    "        sclip:       number of pixels to be replaced at beginning of spectrum  (bit 3)\n",
    "        eclip:       number of pixels to be replaced at end of spectrum   (bit 3)\n",
    "        thresh:      threshold for identifying smaller spikes  (bit 2 set if spike)\n",
    "                     (value independent of absolute pixel value; 10000 too aggressive?) \n",
    "        bit2flag:    True: interpolate the value of pixels masked in bit 2 (a.k.a., the pixels identified in the file header comment section)\n",
    "                     False: ignore...\n",
    "    \n",
    "    Function created after test notebook: notebooks/STO2/EtaCar/EtaCar2_spike_cleaning_single_spectrum_v4_testing.ipynb\n",
    "        \n",
    "    initially created: 8/21/2019, VTO\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Step 1\n",
    "    \n",
    "    # identify the large spikes and set mask\n",
    "    # set bit 3 for \"end of spectrum outliers\"\n",
    "    dtt = type(ispec1)\n",
    "    if type(ispec1)==type(np.zeros(2)):\n",
    "        spec1 = ispec1.copy()\n",
    "    else:\n",
    "        spec1 = ispec1.value\n",
    "    mask1 = imask1.copy()\n",
    "    if verbose: print(spec1.shape)\n",
    "    \n",
    "    # Step 1\n",
    "    # clip ends of scan first in case there are major spikes.\n",
    "    # set bit 3\n",
    "    if sclip>0:\n",
    "        #sclip = 70\n",
    "        # replace the beginning sclip pixels with the value of the next inside pixel\n",
    "        if spec1[sclip] < 0.5E9:\n",
    "            spec1[:sclip] = np.ones(sclip) * spec1[sclip]\n",
    "            # set the mask\n",
    "            mask1[:sclip] = np.bitwise_or(mask1[:sclip], 8)   \n",
    "        else:\n",
    "            print('Error. repSpike1D: spectrum in pixel sclip is spike.')\n",
    "        \n",
    "    if np.abs(eclip)>0:\n",
    "        #eclip = -100\n",
    "        \n",
    "        # replace the eclip pixels at end of scan with the value of the pixel at eclip-1\n",
    "        if spec1[eclip] < 0.5E9:\n",
    "            spec1[eclip:] = np.ones(np.abs(eclip)) * spec1[eclip]\n",
    "            # set the mask\n",
    "            mask1[eclip:] = np.bitwise_or(mask1[eclip:], 8)   \n",
    "        else:\n",
    "            print('Error. repSpike1D: spectrum in pixel eclip is spike.')\n",
    "            \n",
    "    # Step 2\n",
    "    # Identify and mask major spikes with counts over 5E8, set to nan.\n",
    "    # set bit 2 for \"new de-spiking\"\n",
    "    args = np.argwhere(spec1 > 0.5e9)\n",
    "    for arg in args:\n",
    "        spec1[arg] = np.nan\n",
    "        mask1[arg] = np.bitwise_or(mask1[arg], 4)\n",
    "        if arg<spec1.size-1:    \n",
    "            spec1[arg+1] = np.nan\n",
    "            mask1[arg+1] = np.bitwise_or(mask1[arg+1], 4)\n",
    "            if arg<spec1.size-2:    \n",
    "                spec1[arg+2] = np.nan\n",
    "                mask1[arg+2] = np.bitwise_or(mask1[arg+2], 4)\n",
    "        if arg>1:\n",
    "            spec1[arg-1] = np.nan\n",
    "            mask1[arg-1] = np.bitwise_or(mask1[arg-1], 4)\n",
    "            if arg>2:\n",
    "                spec1[arg-2] = np.nan\n",
    "                mask1[arg-2] = np.bitwise_or(mask1[arg-2], 4)\n",
    "    idx = np.arange(spec1.size)\n",
    "    \n",
    "    try:\n",
    "        # get the nan groups:\n",
    "        midx = idx[np.where(mask1==4)]\n",
    "        gmidx = list(groupSequence(midx))\n",
    "\n",
    "        seps = [gmidx[0][0]]\n",
    "        for i in range(len(gmidx)-1): seps.append(gmidx[i+1][0] - gmidx[i][-1])\n",
    "        seps.append(spec1.size - gmidx[-1][-1])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #if verbose: print('Separations of groups: ', seps)\n",
    "    \n",
    "    # create an index array for the spectrum (e.g., replacement for velocity array)\n",
    "    pidx  = np.arange(spec1.shape[0])\n",
    "    pidx1 = np.arange(spec1.shape[0])\n",
    "    \n",
    "    # group all pixels with mask flag 4 (or flag2 and flag 4 but not flag 8)\n",
    "    mpidx1 = pidx[np.where(np.bitwise_and(mask1, 4))]\n",
    "    if bit2flag:\n",
    "        mpidx1 = pidx[(np.bitwise_and(mask1, 2)|np.bitwise_and(mask1, 4))&(np.bitwise_and(mask1, 8))]\n",
    "    if mpidx1.size>0:\n",
    "        gmidx1 = list(groupSequence(mpidx1))\n",
    "        n_gmidx1 = len(gmidx1)\n",
    "        \n",
    "        seps1 = [gmidx1[0][0]]\n",
    "        for i in range(len(gmidx1)-1): seps1.append(gmidx1[i+1][0] - gmidx1[i][-1])\n",
    "        seps1.append(spec1.size - gmidx1[-1][-1])\n",
    "    else:\n",
    "        n_gmidx1 = 0\n",
    "        \n",
    "    # interpolation parameters\n",
    "    s=0.0   # smoothing condition, if 0.0, do interpolation if no weights provided\n",
    "    k=3     # order of spline fit -> use cubic splines\n",
    "    \n",
    "    for i in range(n_gmidx1):\n",
    "        g0 = gmidx1[i]   # get i-th group\n",
    "        ps = g0[0]       # first element in group\n",
    "        pe = g0[-1]      # last element in group\n",
    "        ds = 30          # repair interval on start side\n",
    "        if ds > seps1[i]: ds = seps1[i]\n",
    "        de = 30          # repair interval on end side\n",
    "        if de > seps1[i+1]: de = seps1[i+1]\n",
    "        ds = int(ds)\n",
    "        de = int(de)\n",
    "        \n",
    "        # the arrays below exclude ps to pe, the range we want to interpolate\n",
    "        isp = np.hstack((spec1[ps-ds:ps],spec1[pe+1:pe+de]))\n",
    "        ipi = np.hstack(( pidx1[ps-ds:ps], pidx1[pe+1:pe+de]))\n",
    "        \n",
    "        # interpolate missing/masked values\n",
    "        if isp.size>3:\n",
    "            it = interpolate.splrep(ipi, isp, k=k)\n",
    "            spec1arep = interpolate.splev(pidx[ps:pe+1], it, der=0)\n",
    "            spec1[ps:pe+1] = spec1arep\n",
    "        else:\n",
    "            print('ERROR: no interpolation of major spikes....')\n",
    "            print(ipi.shape, isp.shape, g0)\n",
    "\n",
    "    ##### Step 3\n",
    "    # Remove additional smaller spikes\n",
    "    # set bit 2 for \"new de-spiking\"\n",
    "    \n",
    "    # median filter option\n",
    "    ks = 7         # median filter kernel\n",
    "    out2 = medfilt(spec1, kernel_size=ks)\n",
    "    \n",
    "    # ALS option\n",
    "    # out3 = als(spec1, lam=0.1, p=0.1)\n",
    "\n",
    "    #thresh = 60000    # spike threshold, spikes below threshold can be removed later.\n",
    "    tsel = np.argwhere((spec1 - out2)>thresh)\n",
    "    # plt.plot(idx[tsel],spec1[tsel],'*')\n",
    "    # mask the small spikes with 4\n",
    "    mask1[tsel] = np.bitwise_or(mask1[tsel], 4)\n",
    "    # remove pixel before and after since we do not know if they are affected.\n",
    "    tsel1 = tsel[np.where((tsel>1)&(tsel<1023))]\n",
    "    mask1[tsel1-1] = np.bitwise_or(mask1[tsel1-1], 4)\n",
    "    mask1[tsel1+1] = np.bitwise_or(mask1[tsel1+1], 4)\n",
    "    if verbose: print('small spikes (bit 2, flag value 4) at (+/-1): ', np.squeeze(tsel))\n",
    "    \n",
    "    ##################\n",
    "    # now, try to interpolate the identified pixels\n",
    "    \n",
    "    mpidx1 = pidx[np.argwhere(np.bitwise_and(mask1, 4))]\n",
    "    n_mpidx1 = len(mpidx1)\n",
    "    \n",
    "    s=0.0\n",
    "    k=3\n",
    "    \n",
    "    for i in range(n_mpidx1):\n",
    "        e0 = int(mpidx1[i])   # get i-th element\n",
    "        #print(i, e0)\n",
    "        ds = int(15)\n",
    "        if ds > e0: ds = e0\n",
    "        de = int(15)\n",
    "        if de > spec1.size: de = int(spec1.size - e0 - 1)\n",
    "        \n",
    "        # the arrays below exclude ps to pe, the range we want to interpolate\n",
    "        e0 = int(e0)\n",
    "        isp = np.squeeze(spec1[e0-ds:e0+de])\n",
    "        ipi =  np.squeeze(pidx1[e0-ds:e0+de])\n",
    "        ims = np.squeeze(mask1[e0-ds:e0+de])\n",
    "        esel = np.argwhere(np.bitwise_and(ims, 4)==0)\n",
    "        esel2 = np.squeeze(np.argwhere(np.bitwise_and(ims, 4)))\n",
    "        ispr = np.squeeze(isp[esel])\n",
    "        ipir = np.squeeze(ipi[esel])\n",
    "        imsr = np.squeeze(ims[esel])\n",
    "        #print(e0, ds, esel2, e0-ds+esel2)\n",
    "        \n",
    "        try:\n",
    "            it = interpolate.splrep(ipir, ispr, k=k)\n",
    "            sprep = np.squeeze(interpolate.splev(ipi[esel2], it, der=0))\n",
    "            #print('   org: ', isp[esel2])\n",
    "            #print(isp)\n",
    "            isp[esel2] = sprep\n",
    "            #print(isp)\n",
    "            #print('   rep: ', spec1a[e0-ds+esel2])\n",
    "            spec1[e0-ds+esel2] = sprep\n",
    "        except:\n",
    "            print(ispr.size)\n",
    "\n",
    "    return spec1, mask1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from itertools import groupby, cycle \n",
    "  \n",
    "def groupSequence(l): \n",
    "    temp_list = cycle(l) \n",
    "    \n",
    "    next(temp_list) \n",
    "    groups = groupby(l, key = lambda j: j + 1 == next(temp_list)) \n",
    "    for k, v in groups: \n",
    "        if k: \n",
    "            yield tuple(v) + (next((next(groups)[1])), ) \n",
    "\n",
    "\n",
    "\n",
    "def addHeaderBadPixels(icom, imask):\n",
    "    \"\"\"\n",
    "    Add the bad pixels listed in the header in the comment section as determined by scooper, the Level 0 to Level 0.5 program.\n",
    "    The flag value for bad pixels here is 2.\n",
    "    \n",
    "    However, the header information should have been added when creating the mask! If it is added again, it should not change \n",
    "    the already existing information in case the functions has been invoked more than once.\n",
    "    \"\"\"\n",
    "    nmask = imask.copy()\n",
    "    try:\n",
    "        #icom = hd1['COMMENT']\n",
    "        com = np.genfromtxt(icom, dtype=None, names=['brd', 'inp', 'chan', 'oldv', 'newv', 'line', 'pixel'],\n",
    "                            delimiter=[3,3,6,12,13,5,5], skip_header=2)\n",
    "\n",
    "        # bit 1 => add 2 to mask: originally despiked in scooper\n",
    "        # first NII line, second NII line, and [OI] line\n",
    "        nmask[0,com['chan'][np.where((com['brd']==1)&(com['inp']==1))]-1] = np.bitwise_or(nmask[0,com['chan'][np.where((com['brd']==1)&(com['inp']==1))]-1], 2)\n",
    "        nmask[1,com['chan'][np.where((com['brd']==1)&(com['inp']==2))]-1] = np.bitwise_or(nmask[1,com['chan'][np.where((com['brd']==1)&(com['inp']==2))]-1], 2)\n",
    "        nmask[2,com['chan'][np.where((com['brd']==3)&(com['inp']==1))]-1] = np.bitwise_or(nmask[2,com['chan'][np.where((com['brd']==3)&(com['inp']==1))]-1], 2)\n",
    "        if verbose: print('2: ', com['chan'][np.where((com['brd']==3)&(com['inp']==1))]-1)\n",
    "    except:\n",
    "        pass\n",
    "    return nmask\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
